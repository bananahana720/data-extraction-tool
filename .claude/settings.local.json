{
  "permissions": {
    "allow": [
      "Bash(pytest:*)",
      "Bash(if [ -d \"venv\" ])",
      "Bash(then source venv/bin/activate)",
      "Bash(elif [ -d \"venv\" ])",
      "Bash([ -f \"venv/Scripts/activate\" ])",
      "Bash(then source venv/Scripts/activate)",
      "Bash(else echo \"Virtual environment not found\")",
      "Bash(fi)",
      "Bash(./venv/Scripts/python.exe -m pytest --version)",
      "Bash(python -m pytest:*)",
      "Bash(./venv/Scripts/python.exe -m pytest:*)",
      "Bash(elif [ -d \".venv\" ])",
      "Bash(then source .venv/bin/activate)",
      "Bash(elif [ -f \"venv/Scripts/activate\" ])"
    ],
    "deny": [],
    "ask": []
  },
  "model": "sonnet",
  "hooks": {
    "PreToolUse": [
      {
        "hooks": [
          {
            "type": "prompt",
            "prompt": "Scan tool input for validation error indicators over sytnax and semantics. Count and track occurrences.\n\n$ARGUMENTS\n\nIf total error indicators >= 2, respond with a:\n```json\n{\n  \"hookEventName\": \"PreToolUse\",\n  \"permissionDecision\": \"block\",\n  \"permissionDecisionReason\": \" Error(s) detected.\",\n  \"additionalContext\": \"[Insert what and why]\"\n}\n```\n\nElse: ```json\n{\n  \"hookEventName\": \"PreToolUse\",\n  \"permissionDecision\": \"allow\"\n}\n```"
          }
        ]
      }
    ],
    "PostToolUse": [
      {
        "matcher": "Edit|Write",
        "hooks": [
          {
            "type": "command",
            "command": "npx prettier --write $FILE_PATH"
          }
        ]
      }
    ],
    "Stop": [
      {
        "hooks": [
          {
            "type": "prompt",
            "prompt": "Evaluate task completion using this checklist. Score each item 0 (no) or 1 (yes):\n\n1. Tool execution succeeded (no errors in transcript)\n2. Output was complete or verified\n3. Files were saved (not just viewed)\n4. Changes address the original request\n\n$ARGUMENTS\n\nSum the scores. If total < 3, respond:\n```json\n{\n  \"hookEventName\": \"Stop\",\n  \"decision\": \"block\",\n  \"reason\": \"Incomplete: [list missing items]\"\n}\n```\n\nIf total >= 3, respond:\n```json\n{\n  \"hookEventName\": \"Stop\",\n  \"decision\": \"approve\",\n  \"reason\": \"Complete\"\n}\n```"
          },
          {
            "type": "command",
            "command": "echo \"$(date): $CONVERSATION_SUMMARY\" >> .claude/activity.log"
          }
        ]
      }
    ],
    "SubagentStop": [
      {
        "hooks": [
          {
            "type": "prompt",
            "prompt": "Did the subagent complete its assigned task? Check:\n\n1. Task name in input: [extract from $ARGUMENTS]\n2. Did the subagent execute relevant tools? (yes/no)\n3. Is there output/result data? (yes/no)\n4. Are there uncaught errors? (yes/no = fail)\n\n$ARGUMENTS\n\nBlock if: #2=no OR #3=no OR #4=yes\nOtherwise approve.\n\nRespond: ```json\n{\n  \"hookEventName\": \"SubagentStop\",\n  \"decision\": \"approve|block\",\n  \"reason\": \"[which check failed]\"\n}\n```"
          }
        ]
      }
    ]
  },
  "outputStyle": "critical-code-reviewer"
}
