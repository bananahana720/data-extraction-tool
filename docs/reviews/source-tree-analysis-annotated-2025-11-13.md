# Source Tree Analysis - Annotated Directory Structure

**Generated**: 2025-11-13
**Project**: Data Extraction Tool (Enterprise Document Processing Pipeline)
**Repository Type**: Monolith with Dual Codebase
**Architecture Pattern**: Modular five-stage pipeline (Extract â†’ Normalize â†’ Chunk â†’ Semantic â†’ Output)

---

## Project Structure Overview

The Data Extraction Tool implements a **dual codebase strategy** during brownfield modernization:

- **GREENFIELD** (`src/data_extract/`): Modern modular architecture following Epic-based development (Python 3.12+, full type safety, pytest)
- **BROWNFIELD** (`src/{cli,core,extractors,...}`): Legacy production code maintained for compatibility during Epic 1-2 migration
- **Both systems coexist** until consolidation is complete (Story 1.4)

---

## Complete Directory Tree with Annotations

```
data-extraction-tool-1/                    # Project root
â”‚
â”œâ”€â”€ src/                                   # Source code (DUAL CODEBASE)
â”‚   â”‚
â”‚   â”œâ”€â”€ data_extract/                      # âœ¨ GREENFIELD: New modular pipeline architecture
â”‚   â”‚   â”‚                                  #    Implements 5-stage processing with frozen dataclasses & ABCs
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ __init__.py                    # Package initialization
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ cli.py                         # â†’ PRIMARY CLI ENTRY POINT (Typer-based)
â”‚   â”‚   â”‚                                  #    data-extract command routes here
â”‚   â”‚   â”‚                                  #    Epic 5 CLI implementation
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ chunk/                         # STAGE 3: Semantic-aware chunking
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚   â”‚                                  # Placeholder for spaCy-based sentence boundary detection
â”‚   â”‚   â”‚                                  # To be implemented in Epic 3 (Story 3.1)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ core/                          # Core abstractions & protocols
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ exceptions.py              # Custom exception hierarchy
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py                  # Frozen dataclasses:
â”‚   â”‚   â”‚   â”‚                              #   - ExtractionResult (Stage 1 output)
â”‚   â”‚   â”‚   â”‚                              #   - ContentBlock (structural units)
â”‚   â”‚   â”‚   â”‚                              #   - ProcessingResult (Stages 2-4 output)
â”‚   â”‚   â”‚   â”‚                              #   - FormattedOutput (Stage 5 output)
â”‚   â”‚   â”‚   â””â”€â”€ pipeline.py                # PipelineStage protocol & orchestration
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ config/                        # Configuration management
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py                # Config loading & schema validation (Epic 5)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ extract/                       # STAGE 1: Format-specific extraction
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ adapter.py                 # Unified extractor interface
â”‚   â”‚   â”‚   â”œâ”€â”€ pdf.py                     # PDF extraction (PyMuPDF + Tesseract fallback)
â”‚   â”‚   â”‚   â”œâ”€â”€ docx.py                    # DOCX extraction (python-docx)
â”‚   â”‚   â”‚   â”œâ”€â”€ excel.py                   # XLSX/XLS extraction (openpyxl)
â”‚   â”‚   â”‚   â”œâ”€â”€ pptx.py                    # PPTX extraction (python-pptx)
â”‚   â”‚   â”‚   â”œâ”€â”€ csv.py                     # CSV extraction (Python csv module)
â”‚   â”‚   â”‚   â””â”€â”€ txt.py                     # TXT extraction (raw text)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ normalize/                     # STAGE 2: Text cleaning & standardization
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ cleaning.py                # Text normalization (whitespace, encoding)
â”‚   â”‚   â”‚   â”œâ”€â”€ entities.py                # Named entity standardization
â”‚   â”‚   â”‚   â”œâ”€â”€ metadata.py                # Content metadata extraction
â”‚   â”‚   â”‚   â”œâ”€â”€ schema.py                  # Schema validation
â”‚   â”‚   â”‚   â”œâ”€â”€ validation.py              # Content validation rules
â”‚   â”‚   â”‚   â”œâ”€â”€ normalizer.py              # Main normalizer orchestrator
â”‚   â”‚   â”‚   â””â”€â”€ config.py                  # Normalization configuration
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ output/                        # STAGE 5: Multi-format output generation
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py                # JSON, TXT, CSV formatters (Epic 3)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ semantic/                      # STAGE 4: Classical NLP analysis
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py                # TF-IDF, LSA (scikit-learn)
â”‚   â”‚   â”‚                                  # No transformers per enterprise constraint
â”‚   â”‚   â”‚                                  # To be implemented in Epic 4
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ utils/                         # Shared utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ nlp.py                     # spaCy lazy-loader & NLP helpers
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ __pycache__/                   # Python bytecode cache
â”‚   â”‚
â”‚   â”œâ”€â”€ cli/                               # ðŸ“¦ BROWNFIELD: Legacy CLI utilities
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ __main__.py                    # Legacy CLI entry point (deprecated)
â”‚   â”‚   â”œâ”€â”€ main.py                        # Legacy command dispatcher
â”‚   â”‚   â”œâ”€â”€ commands.py                    # Legacy command handlers
â”‚   â”‚   â””â”€â”€ progress_display.py            # Legacy progress UI (Rich)
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                              # ðŸ“¦ BROWNFIELD: Legacy core modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ interfaces.py                  # Abstract base classes
â”‚   â”‚   â””â”€â”€ models.py                      # Legacy data models
â”‚   â”‚
â”‚   â”œâ”€â”€ extractors/                        # ðŸ“¦ BROWNFIELD: Legacy format extractors
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ pdf_extractor.py               # Legacy PDF extraction
â”‚   â”‚   â”œâ”€â”€ docx_extractor.py              # Legacy DOCX extraction
â”‚   â”‚   â”œâ”€â”€ excel_extractor.py             # Legacy Excel extraction
â”‚   â”‚   â”œâ”€â”€ pptx_extractor.py              # Legacy PPTX extraction
â”‚   â”‚   â”œâ”€â”€ csv_extractor.py               # Legacy CSV extraction
â”‚   â”‚   â””â”€â”€ txt_extractor.py               # Legacy text extraction
â”‚   â”‚
â”‚   â”œâ”€â”€ processors/                        # ðŸ“¦ BROWNFIELD: Legacy processing modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ context_linker.py              # Context preservation
â”‚   â”‚   â”œâ”€â”€ metadata_aggregator.py         # Metadata collection
â”‚   â”‚   â””â”€â”€ quality_validator.py           # Quality assurance
â”‚   â”‚
â”‚   â”œâ”€â”€ formatters/                        # ðŸ“¦ BROWNFIELD: Legacy output formatters
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ json_formatter.py              # JSON output
â”‚   â”‚   â”œâ”€â”€ markdown_formatter.py          # Markdown output
â”‚   â”‚   â””â”€â”€ chunked_text_formatter.py      # Chunked text output
â”‚   â”‚
â”‚   â”œâ”€â”€ infrastructure/                    # ðŸ“¦ BROWNFIELD: Legacy infrastructure
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ logging_framework.py           # Structured logging (structlog)
â”‚   â”‚   â”œâ”€â”€ config_manager.py              # Configuration management
â”‚   â”‚   â”œâ”€â”€ error_handler.py               # Error handling & recovery
â”‚   â”‚   â””â”€â”€ progress_tracker.py            # Progress monitoring
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/                          # ðŸ“¦ BROWNFIELD: Legacy pipeline orchestration
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ extraction_pipeline.py         # Main pipeline workflow
â”‚   â”‚   â””â”€â”€ batch_processor.py             # Batch processing engine
â”‚   â”‚
â”‚   â””â”€â”€ data_extraction_tool.egg-info/     # Setuptools generated metadata
â”‚
â”œâ”€â”€ tests/                                 # Test suite (pytest with markers)
â”‚   â”‚
â”‚   â”œâ”€â”€ __pycache__/                       # Python bytecode cache
â”‚   â”‚
â”‚   â”œâ”€â”€ conftest.py                        # [MISSING - to be created with pytest fixtures]
â”‚   â”‚
â”‚   â”œâ”€â”€ fixtures/                          # Test data & fixtures (90+ MB)
â”‚   â”‚   â”œâ”€â”€ README.md                      # Fixture documentation & regeneration scripts
â”‚   â”‚   â”œâ”€â”€ archer/                        # Real-world sample documents
â”‚   â”‚   â”œâ”€â”€ docx/                          # DOCX test fixtures
â”‚   â”‚   â”œâ”€â”€ excel/                         # XLSX test fixtures
â”‚   â”‚   â”œâ”€â”€ images/                        # Image test fixtures
â”‚   â”‚   â”œâ”€â”€ pdfs/                          # PDF test fixtures
â”‚   â”‚   â”‚   â”œâ”€â”€ large/                     # Large PDF samples (100+ MB)
â”‚   â”‚   â”‚   â””â”€â”€ scanned/                   # Scanned PDF (OCR test cases)
â”‚   â”‚   â”œâ”€â”€ edge-cases/                    # Edge case test data
â”‚   â”‚   â”‚   â”œâ”€â”€ docx/
â”‚   â”‚   â”‚   â”œâ”€â”€ malformed/                 # Corrupted/invalid files
â”‚   â”‚   â”‚   â”œâ”€â”€ pdf/
â”‚   â”‚   â”‚   â”œâ”€â”€ pptx/
â”‚   â”‚   â”‚   â”œâ”€â”€ txt/
â”‚   â”‚   â”‚   â””â”€â”€ xlsx/
â”‚   â”‚   â”œâ”€â”€ normalization/                 # Text normalization test data
â”‚   â”‚   â”‚   â”œâ”€â”€ dirty_text_samples/
â”‚   â”‚   â”‚   â””â”€â”€ expected_clean_outputs/
â”‚   â”‚   â”œâ”€â”€ real-world-files/              # Production document samples
â”‚   â”‚   â”œâ”€â”€ stress_output/                 # Performance test outputs
â”‚   â”‚   â””â”€â”€ batch_output_*/                # Batch processing test outputs
â”‚   â”‚
â”‚   â”œâ”€â”€ unit/                              # Fast unit tests (isolated, <100ms each)
â”‚   â”‚   â”œâ”€â”€ test_extract/                  # GREENFIELD: Stage 1 extractor tests
â”‚   â”‚   â”‚   â”œâ”€â”€ test_pdf.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_docx.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_excel.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_pptx.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_csv.py
â”‚   â”‚   â”‚   â””â”€â”€ test_txt.py
â”‚   â”‚   â”œâ”€â”€ test_normalize/                # GREENFIELD: Stage 2 normalizer tests
â”‚   â”‚   â”‚   â”œâ”€â”€ test_cleaning.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_entities.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_validation.py
â”‚   â”‚   â”‚   â””â”€â”€ test_schema.py
â”‚   â”‚   â”œâ”€â”€ test_utils/                    # GREENFIELD: Utility tests
â”‚   â”‚   â”‚   â””â”€â”€ test_nlp.py
â”‚   â”‚   â”œâ”€â”€ cli/                           # BROWNFIELD: CLI tests
â”‚   â”‚   â”œâ”€â”€ core/                          # BROWNFIELD: Core module tests
â”‚   â”‚   â”œâ”€â”€ extractors/                    # BROWNFIELD: Extractor tests
â”‚   â”‚   â”œâ”€â”€ formatters/                    # BROWNFIELD: Formatter tests
â”‚   â”‚   â”œâ”€â”€ infrastructure/                # BROWNFIELD: Infrastructure tests
â”‚   â”‚   â”œâ”€â”€ pipeline/                      # BROWNFIELD: Pipeline tests
â”‚   â”‚   â””â”€â”€ processors/                    # BROWNFIELD: Processor tests
â”‚   â”‚
â”‚   â”œâ”€â”€ integration/                       # Multi-component end-to-end tests
â”‚   â”‚   â”œâ”€â”€ test_pipeline.py               # Complete 5-stage pipeline tests
â”‚   â”‚   â”œâ”€â”€ test_extraction_pipeline.py    # Brownfield pipeline integration
â”‚   â”‚   â””â”€â”€ [other integration test files]
â”‚   â”‚
â”‚   â”œâ”€â”€ performance/                       # Performance benchmarks & stress tests
â”‚   â”‚   â”œâ”€â”€ batch_100_files/               # 100-file batch test data
â”‚   â”‚   â”‚   â”œâ”€â”€ docx/
â”‚   â”‚   â”‚   â”œâ”€â”€ mixed/
â”‚   â”‚   â”‚   â”œâ”€â”€ pdfs/
â”‚   â”‚   â”‚   â””â”€â”€ xlsx/
â”‚   â”‚   â”œâ”€â”€ [performance test files]
â”‚   â”‚   â””â”€â”€ [markers: -m "not slow" skips slow tests]
â”‚   â”‚
â”‚   â”œâ”€â”€ validation/                        # UAT validation tests
â”‚   â”œâ”€â”€ outputs/                           # Test execution outputs
â”‚   â”œâ”€â”€ test_cli/                          # [DEPRECATING - move to unit/cli]
â”‚   â”œâ”€â”€ test_edge_cases/                   # [DEPRECATING - consolidating to fixtures]
â”‚   â”œâ”€â”€ test_extractors/                   # [CONSOLIDATING to unit/]
â”‚   â”œâ”€â”€ test_formatters/                   # [CONSOLIDATING to unit/]
â”‚   â”œâ”€â”€ test_infrastructure/               # [CONSOLIDATING to unit/]
â”‚   â”œâ”€â”€ test_pipeline/                     # [CONSOLIDATING to unit/]
â”‚   â”œâ”€â”€ test_processors/                   # [CONSOLIDATING to unit/]
â”‚   â””â”€â”€ __pycache__/
â”‚
â”œâ”€â”€ docs/                                  # Comprehensive documentation (90+ files)
â”‚   â”‚                                      #    Organized by epic, story, and domain
â”‚   â”‚
â”‚   â”œâ”€â”€ README.md                          # Main architecture documentation
â”‚   â”œâ”€â”€ architecture.md                    # Technical architecture & ADRs
â”‚   â”œâ”€â”€ epics.md                           # Epic roadmap & breakdown
â”‚   â”‚
â”‚   â”œâ”€â”€ .archive/                          # ARCHIVED: Pre-BMAD documentation
â”‚   â”‚                                      #    165+ legacy files (2025-11-13 cleanup)
â”‚   â”‚
â”‚   â”œâ”€â”€ PRD.md                             # Product Requirements Document
â”‚   â”œâ”€â”€ tech-spec-epic-1.md                # Epic 1 technical specification
â”‚   â”œâ”€â”€ tech-spec-epic-2.md                # Epic 2 technical specification
â”‚   â”œâ”€â”€ tech-spec-epic-2.5.md              # Epic 2.5 (Refinement & Quality)
â”‚   â”‚
â”‚   â”œâ”€â”€ stories/                           # Story-level implementation specs
â”‚   â”‚   â”œâ”€â”€ 1.1-project-infrastructure.md
â”‚   â”‚   â”œâ”€â”€ 1.2-brownfield-assessment.md
â”‚   â”‚   â”œâ”€â”€ 1.3-testing-framework.md
â”‚   â”‚   â”œâ”€â”€ 1.4-core-pipeline-consolidation.md
â”‚   â”‚   â”œâ”€â”€ 2.1-pdf-extraction.md
â”‚   â”‚   â”œâ”€â”€ 2.2-docx-extraction.md
â”‚   â”‚   â”œâ”€â”€ 2.3-schema-standardization.md
â”‚   â”‚   â”œâ”€â”€ 2.4-text-cleaning.md
â”‚   â”‚   â”œâ”€â”€ 2.5-*.md                      # Epic 2.5 quality refinement stories
â”‚   â”‚   â””â”€â”€ [other story files]
â”‚   â”‚
â”‚   â”œâ”€â”€ brownfield-assessment.md           # Complete legacy code analysis
â”‚   â”œâ”€â”€ ci-cd-pipeline.md                  # CI/CD workflow & configuration
â”‚   â”œâ”€â”€ ci-cd-infrastructure-analysis.md   # GitHub Actions setup details
â”‚   â”‚
â”‚   â”œâ”€â”€ uat/                               # User Acceptance Testing framework
â”‚   â”‚   â”œâ”€â”€ test-cases/                    # Generated UAT test specifications
â”‚   â”‚   â”œâ”€â”€ test-context/                  # Test infrastructure context (XML)
â”‚   â”‚   â”œâ”€â”€ test-results/                  # Test execution results
â”‚   â”‚   â”œâ”€â”€ reviews/                       # QA review & approval reports
â”‚   â”‚   â””â”€â”€ tmux-cli-windows-setup.md      # Windows tmux-cli guidance
â”‚   â”‚
â”‚   â”œâ”€â”€ traceability-*.md                  # Epic-to-implementation traceability
â”‚   â”œâ”€â”€ performance-baselines-*.md         # NFR baseline measurements
â”‚   â”œâ”€â”€ TESTING-README.md                  # Test organization & patterns
â”‚   â”œâ”€â”€ LOGGING_GUIDE.md                   # Logging infrastructure docs
â”‚   â”œâ”€â”€ ERROR_HANDLING_GUIDE.md            # Error handling patterns
â”‚   â”œâ”€â”€ troubleshooting-spacy.md           # spaCy setup & troubleshooting
â”‚   â”œâ”€â”€ tmux-cli-instructions.md           # tmux-cli reference & usage
â”‚   â”‚
â”‚   â”œâ”€â”€ audit-report-*.md                  # Workflow audit reports (BMAD generated)
â”‚   â”œâ”€â”€ housekeeping-findings-2025-11-13.md # Documentation cleanup summary
â”‚   â””â”€â”€ [40+ other reference docs]
â”‚
â”œâ”€â”€ scripts/                               # Development & utility scripts
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚
â”‚   â”œâ”€â”€ profile_pipeline.py                # Performance profiling utility
â”‚   â”‚                                      #   - get_total_memory() for process monitoring
â”‚   â”‚                                      #   - baseline establishment (Story 2.5.1)
â”‚   â”‚
â”‚   â”œâ”€â”€ run_performance_suite.py           # Batch performance testing
â”‚   â”œâ”€â”€ run_test_extractions.py            # Extract test runner
â”‚   â”‚
â”‚   â”œâ”€â”€ generate_large_pdf_fixture.py      # Fixture generation helpers
â”‚   â”œâ”€â”€ generate_large_excel_fixture.py
â”‚   â”œâ”€â”€ generate_scanned_pdf_fixture.py
â”‚   â”œâ”€â”€ create_performance_batch.py
â”‚   â”‚
â”‚   â”œâ”€â”€ build_package.sh                   # Package build (Linux/macOS)
â”‚   â”œâ”€â”€ build_package.bat                  # Package build (Windows)
â”‚   â”œâ”€â”€ verify_package.sh                  # Package verification
â”‚   â”œâ”€â”€ create_dev_package.sh              # Dev environment setup
â”‚   â”‚
â”‚   â”œâ”€â”€ test_installation.py               # Installation validation
â”‚   â”œâ”€â”€ validate_installation.py
â”‚   â”œâ”€â”€ check_package_contents.py
â”‚   â”‚
â”‚   â”œâ”€â”€ diagnose_ocr.py                    # OCR diagnostics
â”‚   â”œâ”€â”€ fix_import_paths.py                # Import path correction
â”‚   â”œâ”€â”€ regenerate_gold_standard.py        # Test baseline regeneration
â”‚   â””â”€â”€ [other utility scripts]
â”‚
â”œâ”€â”€ config/                                # Configuration templates & schemas
â”‚   â””â”€â”€ normalize/                         # Normalization config (Story 2.3)
â”‚       â””â”€â”€ [YAML/JSON schemas]
â”‚
â”œâ”€â”€ examples/                              # Usage examples & documentation
â”‚   â”œâ”€â”€ README.md                          # Example guide
â”‚   â”œâ”€â”€ minimal_extractor.py               # Minimal extractor usage
â”‚   â”œâ”€â”€ minimal_processor.py               # Minimal processor usage
â”‚   â”œâ”€â”€ simple_pipeline.py                 # Simple pipeline example
â”‚   â”œâ”€â”€ pdf_extractor_example.py           # Format-specific examples
â”‚   â”œâ”€â”€ docx_extractor_example.py
â”‚   â”œâ”€â”€ excel_extractor_example.py
â”‚   â”œâ”€â”€ pptx_extractor_example.py
â”‚   â”œâ”€â”€ docx_with_logging.py               # Logging integration example
â”‚   â”œâ”€â”€ logging_example.py
â”‚   â”œâ”€â”€ processor_pipeline_example.py      # Pipeline composition example
â”‚   â”œâ”€â”€ formatter_examples.py              # Output formatting examples
â”‚   â””â”€â”€ sample_input.*                     # Sample input files
â”‚
â”œâ”€â”€ bmad/                                  # BMAD Workflow System (Brownfield Modernization)
â”‚   â”‚                                      #    Epic-based development framework
â”‚   â”œâ”€â”€ workflows/                         # BMAD workflows (create-story, dev-story, etc.)
â”‚   â”œâ”€â”€ agents/                            # BMAD agents (dev, qa, pm, architect, etc.)
â”‚   â”œâ”€â”€ modules/                           # BMAD modules (bmm, cis, etc.)
â”‚   â””â”€â”€ [BMAD configuration]
â”‚
â”œâ”€â”€ .github/                               # GitHub configuration
â”‚   â””â”€â”€ workflows/                         # CI/CD automation
â”‚       â”œâ”€â”€ test.yml                       # pytest suite (unit + integration + performance)
â”‚       â”œâ”€â”€ performance.yml                # Performance regression testing
â”‚       â””â”€â”€ performance-regression.yml     # Continuous performance monitoring
â”‚
â”œâ”€â”€ .claude/                               # Claude Code configuration
â”‚   â”œâ”€â”€ CLAUDE.md                          # Project-specific instructions (THIS FILE)
â”‚   â”œâ”€â”€ commands/                          # Custom slash commands
â”‚   â”‚   â””â”€â”€ bmad/                          # BMAD workflow shortcuts
â”‚   â””â”€â”€ hooks/                             # Pre-commit/post-commit hooks
â”‚
â”œâ”€â”€ .mypy_cache/                           # Type checker cache
â”œâ”€â”€ .pytest_cache/                         # pytest cache
â”œâ”€â”€ .ruff_cache/                           # ruff linter cache
â”‚
â”œâ”€â”€ venv/                                  # Python virtual environment (local dev)
â”‚
â”œâ”€â”€ dist/                                  # Built distributions
â”œâ”€â”€ htmlcov/                               # HTML coverage reports
â”œâ”€â”€ logs/                                  # Application logs
â”œâ”€â”€ output/                                # Sample output directory
â”‚
â”œâ”€â”€ .gitignore                             # Git ignore rules
â”œâ”€â”€ .pre-commit-config.yaml                # Pre-commit hooks configuration
â”‚
â”œâ”€â”€ pyproject.toml                         # â†’ PROJECT CONFIGURATION (setuptools)
â”‚                                          #    Entry points, dependencies, tool configs
â”‚
â”œâ”€â”€ setup.py                               # Legacy setup.py (pyproject.toml preferred)
â”œâ”€â”€ MANIFEST.in                            # Package manifest
â”‚
â”œâ”€â”€ pytest.ini                             # pytest configuration & markers
â”œâ”€â”€ README.md                              # Project overview & quickstart
â”‚
â”œâ”€â”€ analyze_profile.py                     # Profile analysis utility
â”œâ”€â”€ create_fixtures.py                     # Fixture creation script
â”‚
â”œâ”€â”€ CLAUDE.md                              # â†’ PROJECT INSTRUCTIONS (for Claude Code)
â”‚                                          #    Architecture, development workflow, commands
â”‚
â”œâ”€â”€ profile.stats                          # Performance profiling data
â”œâ”€â”€ test.log                               # Test execution logs
â”œâ”€â”€ NUL / cli_test_results.txt             # Test output artifacts
â”œâ”€â”€ .coverage.*                            # Coverage reports (by Python process)
â”‚
â””â”€â”€ TRASH/                                 # Cleanup staging area
    â””â”€â”€ TRASH-FILES.md                     # Archive manifest
```

---

## Critical Folders Explained

### Greenfield Architecture (`src/data_extract/`)

The modern modular five-stage pipeline implementing enterprise-grade document processing:

1. **Extract Stage** (`extract/`) - Format-specific extractors (PDF, DOCX, XLSX, PPTX, CSV, TXT)
   - Unified interface via `adapter.py`
   - PyMuPDF for PDFs + Tesseract fallback for OCR
   - Returns `ExtractionResult` frozen dataclass

2. **Normalize Stage** (`normalize/`) - Text cleaning & standardization
   - Text cleaning (whitespace, encoding normalization)
   - Entity standardization & validation
   - Metadata extraction
   - Returns `ProcessingResult` preserving structure

3. **Chunk Stage** (`chunk/`) - Semantic-aware chunking (Epic 3)
   - spaCy-based sentence boundary detection
   - Placeholder pending implementation

4. **Semantic Stage** (`semantic/`) - Classical NLP analysis (Epic 4)
   - TF-IDF & LSA via scikit-learn
   - No transformer models (enterprise constraint)

5. **Output Stage** (`output/`) - Multi-format generation
   - JSON, TXT, CSV formatters
   - Pending Epic 3 implementation

**Design Patterns**:
- Frozen dataclasses for immutability
- ABC interfaces for extensibility
- Type hints throughout (mypy strict mode)
- Comprehensive test mirrors structure

### Brownfield Legacy (`src/{cli,core,extractors,...}`)

Production code maintained during modernization (Story 1.2 assessment):

- **`cli/`** - Legacy Click-based CLI (pre-Typer)
- **`core/`** - Abstract interfaces & legacy models
- **`extractors/`** - Original format extractors (being modernized)
- **`processors/`** - Content processors (context linker, metadata aggregator, QA)
- **`formatters/`** - Output generators (JSON, Markdown, chunked text)
- **`infrastructure/`** - Logging, config, error handling, progress tracking
- **`pipeline/`** - Batch processor & pipeline orchestration

**Status**: Both systems coexist. Greenfield code supersedes brownfield during Epic consolidation (Story 1.4).

### Test Organization (`tests/`)

**Structure mirrors `src/`**:

- **`unit/`** - Fast isolated tests (markers: unit, extraction, processing, formatting, cli)
  - Test discovery: `test_*.py` files with `test_*()` functions
  - Fixtures in `conftest.py` (shared across tests)

- **`integration/`** - Multi-component workflows
  - End-to-end pipeline validation
  - Markers: integration, pipeline

- **`performance/`** - Benchmarks & stress tests
  - Batch processing (100+ files)
  - NFR validation against baselines
  - Markers: performance, slow

- **`fixtures/`** - Test data (90+ MB)
  - Real-world samples, edge cases, large files
  - Organized by format & test category
  - Regeneration scripts provided

**Coverage Requirements**:
- Epic 1: >60% baseline (enforced in CI)
- Epic 2-4: >80% overall
- Epic 5: >90% critical paths

### Documentation (`docs/`)

**Organized by domain**:

- **Epics & Stories**: `epics.md`, `tech-spec-*.md`, `stories/` directory
- **Architecture**: `architecture.md`, `PRD.md`, ADRs
- **Implementation**: `brownfield-assessment.md`, traceability matrices
- **Operations**: CI/CD docs, testing guides, logging setup, troubleshooting
- **UAT Framework**: `uat/` with test cases, context, results, reviews
- **Archive**: `.archive/` with 165+ pre-BMAD files (legacy documentation)

### Scripts (`scripts/`)

Development utilities for:

- **Performance analysis** (`profile_pipeline.py`, `run_performance_suite.py`)
  - Baselines established in Story 2.5.1
  - Memory monitoring via `get_total_memory()` helper

- **Fixture generation** (`generate_*_fixture.py`)
  - Large PDF/Excel/scanned PDF creation
  - Batch test data generation

- **Installation & validation** (`test_installation.py`, `validate_installation.py`)
  - Package integrity checks

- **Build automation** (`build_package.sh/bat`)
  - Platform-specific build tooling

---

## Entry Points & Key Integration Points

### Primary Entry Points

1. **CLI Entry Point**: `src/data_extract/cli.py` â†’ `data-extract` command
   - Configured in `pyproject.toml` line 90: `data-extract = "data_extract.cli:app"`
   - Typer-based modern CLI
   - Epic 5 implementation

2. **Python Package Entry Point**: `src/data_extract/__init__.py`
   - Public API export for programmatic usage

3. **Brownfield Legacy Entry**: `src/cli/__main__.py` (deprecated)
   - Original Click-based CLI

4. **Testing Entry**: `pytest.ini` configuration
   - Markers: unit, integration, performance, slow, extraction, processing, formatting, pipeline, cli
   - Coverage threshold: 60% (enforced in CI)

### Integration Architecture

**Greenfield â†” Brownfield Bridge**:

During Epic 1-2 modernization, both systems run in parallel:

```
CLI Invocation
    â†“
src/data_extract/cli.py (Typer)
    â†“
PipelineStage Protocol (ABC)
    â”œâ”€ Extract Stage â†’ ExtractionResult
    â”œâ”€ Normalize Stage â†’ ProcessingResult
    â”œâ”€ Chunk Stage â†’ ProcessingResult
    â”œâ”€ Semantic Stage â†’ ProcessingResult
    â””â”€ Output Stage â†’ FormattedOutput

Legacy System (brownfield):
    â†“
src/cli/main.py (Click)
    â†“
extraction_pipeline.py â†’ batch_processor.py
```

**Story 1.4** consolidates both into single modern pipeline.

### Data Flow

```
Input Documents
    â†“
Extract Stage (format-specific)
    â†“ ExtractionResult
Normalize Stage (cleaning & standardization)
    â†“ ProcessingResult
Chunk Stage (semantic boundaries) [Epic 3]
    â†“ ProcessingResult
Semantic Stage (TF-IDF, LSA) [Epic 4]
    â†“ ProcessingResult
Output Stage (JSON/TXT/CSV) [Epic 3]
    â†“ FormattedOutput
```

---

## Dependency & Configuration Cascade

### pyproject.toml (Line 89-90)

```toml
[project.scripts]
data-extract = "data_extract.cli:app"
```

Maps CLI command â†’ entry point module

### Python Version

- **Mandatory**: Python 3.12+ (enterprise requirement per CLAUDE.md)
- Configured in `pyproject.toml` line 10: `requires-python = ">=3.12"`

### Test Configuration (`pytest.ini`)

```ini
testpaths = ["tests"]
addopts = "-v --cov=src --cov-report=term-missing"
markers = [
    performance, slow, unit, integration, extraction,
    processing, formatting, pipeline, cli
]
```

### Pre-commit Hooks (`.pre-commit-config.yaml`)

**Quality gates** (enforced before commit):
1. Black formatting (100 char lines)
2. Ruff linting
3. mypy type checking (strict mode on greenfield only)

Run before push: `pre-commit run --all-files`

---

## Directory Structure Summary Table

| Directory | Purpose | Type | Status |
|-----------|---------|------|--------|
| `src/data_extract/` | Modern modular pipeline | Greenfield | âœ… Active development |
| `src/cli/` | Legacy CLI wrapper | Brownfield | ðŸ“¦ Maintained, deprecating |
| `src/core/` | Legacy interfaces | Brownfield | ðŸ“¦ Maintained |
| `src/extractors/` | Legacy extractors | Brownfield | ðŸ“¦ Being modernized |
| `src/processors/` | Processing modules | Brownfield | ðŸ“¦ Maintained |
| `src/formatters/` | Output generators | Brownfield | ðŸ“¦ Being modernized |
| `src/infrastructure/` | Logging, config, errors | Brownfield | ðŸ“¦ Maintained |
| `src/pipeline/` | Batch orchestration | Brownfield | ðŸ“¦ Being consolidated |
| `tests/unit/` | Unit tests | Testing | âœ… Active |
| `tests/integration/` | E2E tests | Testing | âœ… Active |
| `tests/performance/` | Benchmarks | Testing | âœ… Active |
| `tests/fixtures/` | Test data | Testing | âœ… 90+ MB data |
| `docs/` | Documentation | Docs | âœ… 90+ files |
| `docs/uat/` | UAT framework | Testing | âœ… Workflows |
| `docs/.archive/` | Legacy docs | Docs | ðŸ“¦ 165+ archived |
| `scripts/` | Dev utilities | DevOps | âœ… Active |
| `.github/workflows/` | CI/CD pipelines | DevOps | âœ… GitHub Actions |
| `config/` | Config templates | Config | âœ… Schemas |
| `examples/` | Usage examples | Docs | âœ… 13 examples |
| `bmad/` | Epic workflows | Automation | âœ… BMAD system |

---

## Key Development Patterns

### Testing Markers

**Run tests selectively**:

```bash
pytest -m unit                    # Fast unit tests only
pytest -m integration            # Integration tests
pytest -m "not slow"             # Skip slow tests
pytest -m "extraction"           # Extraction-specific
```

### Type Checking

```bash
mypy src/data_extract/           # Type check greenfield (strict)
# Brownfield excluded per pyproject.toml
```

### Code Quality

```bash
black src/ tests/                # Format (100 char lines)
ruff check src/ tests/           # Lint
pre-commit run --all-files       # All hooks
```

### Performance Profiling

```bash
python scripts/profile_pipeline.py
python scripts/run_performance_suite.py
```

### Fixture Generation

```bash
python scripts/generate_large_pdf_fixture.py
python scripts/generate_large_excel_fixture.py
python scripts/generate_scanned_pdf_fixture.py
python scripts/create_performance_batch.py
```

---

## Architecture Decision Records (ADRs)

- **ADR-001**: Immutable frozen dataclasses prevent pipeline state corruption
- **ADR-002**: Pluggable extractors via ABC isolate format-specific logic
- **ADR-003**: ContentBlocks preserve document structure over raw text
- **ADR-004**: Classical NLP only (scikit-learn, no transformers - enterprise constraint)
- **ADR-005**: Gradual brownfield modernization without breaking production

See `docs/architecture.md` for full decision rationale.

---

## CI/CD Pipeline Structure

**GitHub Actions Workflows** (`.github/workflows/`):

1. **test.yml** - Main test suite
   - Unit + integration + performance tests
   - Coverage threshold: 60%
   - Runs on push & PR

2. **performance.yml** - Regression testing
   - Compares against baseline (Story 2.5.1)
   - NFR validation (P1: <10 min/100 PDFs, P2: <2GB memory)

3. **performance-regression.yml** - Continuous monitoring
   - Scheduled runs
   - Deviation alerts

---

## Documentation Navigation

**Start Here**:
1. `README.md` - Project overview
2. `CLAUDE.md` - Development guide
3. `docs/PRD.md` - Product vision
4. `docs/epics.md` - Implementation roadmap

**Technical Deep Dives**:
- `docs/architecture.md` - System design
- `docs/tech-spec-epic-*.md` - Story-level specs
- `docs/brownfield-assessment.md` - Legacy code analysis

**Operations**:
- `docs/ci-cd-pipeline.md` - CI/CD details
- `docs/TESTING-README.md` - Test patterns
- `docs/troubleshooting-spacy.md` - spaCy setup

**UAT & Quality**:
- `docs/uat/` - Test case generation, execution, review
- `docs/performance-baselines-*.md` - NFR measurements
- `docs/traceability-*.md` - Epic-to-code traceability

---

## Legend

- **âœ…** - Active/current implementation
- **ðŸ“¦** - Maintenance mode (brownfield)
- **âš ï¸** - Planned/deprecated
- **â†’** - Entry point / key file
- **âœ¨** - Greenfield (new modular code)

---

## Summary

The Data Extraction Tool implements a **dual-codebase modernization strategy**:

- **Greenfield** (`src/data_extract/`): Modern 5-stage modular pipeline with frozen dataclasses, ABC protocols, and full type safety
- **Brownfield** (`src/{cli,core,extractors,...}`): Production code maintained for compatibility during migration
- **Both coexist** during Epic 1-2, consolidating in Story 1.4

The architecture prioritizes:
1. **Modularity** - Composable stages with clear interfaces
2. **Type Safety** - Full type hints + mypy strict mode (greenfield only)
3. **Testability** - Comprehensive test suite mirroring src/ structure
4. **Immutability** - Frozen dataclasses prevent state corruption
5. **Enterprise Constraints** - Classical NLP only, no transformers

See `docs/architecture.md` for full technical details.

---

**Document Generated**: 2025-11-13
**BMAD System Integration**: Epic 1-2 brownfield modernization (Story 1.2-1.4)
**Python Version**: 3.12+ (mandatory)
**Quality Gates**: Pre-commit + CI enforcement
