# Story 3.5.5: Model/Cache ADR (Architecture Decision Record)

Status: todo - Ready for implementation (Epic 3.5 - Bridge Epic)

## Story

As a **developer implementing Epic 4 semantic analysis with trained models**,
I want **an Architecture Decision Record documenting model storage, caching, and versioning strategies**,
so that **I can implement consistent, performant model management across the pipeline**.

## Context Summary

**Epic Context:** Story 3.5.5 is part of Epic 3.5 (Bridge Epic - Tooling & Semantic Prep), which prepares the project for Epic 4 (Foundational Semantic Analysis). This story addresses a preparation task from the Epic 3 retrospective: "Model/Cache ADR (Owner: Winston, Est: 4h)."

**Business Value:**
- Prevents ad-hoc model caching decisions that create tech debt (centralized ADR)
- Ensures semantic models load efficiently (TF-IDF vectorizers, LSA models cached)
- Defines model versioning strategy for reproducibility (provenance requirement)
- Avoids Epic 4 mid-story architecture debates (decisions made upfront)
- Enables multi-developer consistency (everyone follows same caching patterns)

**Dependencies:**
- **Story 3.5.4 (Semantic Dependencies)** - scikit-learn, joblib installed and validated
- **Story 2.5.2 (spaCy Integration)** - spaCy model caching precedent (en_core_web_md)
- **ADR-001 through ADR-011** - Existing architecture decisions (immutability, etc.)
- **Epic 4 Requirements:** TF-IDF vectorizers, LSA models, similarity matrices need caching

**Technical Foundation:**
- **joblib** - Python library for efficient model serialization (pickle alternative)
- **spaCy caching pattern** - Lazy load + global cache from Story 2.5.2 (precedent)
- **File system paths** - ~/.data-extract/models/ for user-level caching
- **Provenance tracking** - Model version metadata for reproducibility
- **Enterprise constraints** - Classical NLP only (no transformer model fine-tuning)

**Key Requirements:**
1. **ADR Document:** Create ADR-012 for model storage and caching
2. **Cache Location:** Define where models are stored (user home vs project-local)
3. **Serialization Format:** Define serialization library (joblib, pickle, custom)
4. **Versioning Strategy:** Define how model versions are tracked (metadata, filenames)
5. **Cache Invalidation:** Define when caches are invalidated (dependency changes, config changes)
6. **Performance Targets:** Define acceptable cache load times (<100ms for models)

## Acceptance Criteria

**AC-3.5.5-1: ADR-012 Document Created (P0 - Critical)**
- ADR file created at `docs/architecture-decisions/ADR-012-model-caching-strategy.md`
- ADR follows standard template:
  - **Status:** Accepted
  - **Context:** Epic 4 semantic analysis needs efficient model caching (TF-IDF, LSA)
  - **Decision:** [Specific caching strategy decisions]
  - **Consequences:** [Performance, maintenance, trade-offs]
  - **Alternatives Considered:** [Other options and why rejected]
- ADR integrated into docs/architecture.md reference list
- **Validation:** Manual review of ADR completeness and clarity
- **UAT Required:** Yes - Architecture review with Winston and Charlie (Epic 4 lead)

**AC-3.5.5-2: Cache Location Decision Documented (P0 - Critical)**
- ADR specifies cache location strategy:
  - **Primary:** User home directory `~/.data-extract/models/` (cross-project sharing)
  - **Fallback:** Project-local `.cache/models/` (when home not writable)
  - **Environment override:** `DATA_EXTRACT_MODEL_CACHE` env var
- Rationale documented:
  - User home enables cross-project model reuse (same corpus → same TF-IDF vocab)
  - Project-local supports CI/CD and restricted environments
  - Environment override supports custom deployment scenarios
- Cache directory structure defined:
  ```
  ~/.data-extract/models/
    tfidf/
      {corpus_hash}_v{version}.joblib
    lsa/
      {corpus_hash}_{n_components}_v{version}.joblib
    metadata/
      {model_id}.json
  ```
- **Validation:** Review with team, validate paths work on Windows/Linux/macOS
- **UAT Required:** Yes - Validate directory structure makes sense

**AC-3.5.5-3: Serialization Format Decision Documented (P0)**
- ADR specifies serialization library: **joblib** (not pickle or custom)
- Rationale documented:
  - joblib optimized for large numpy arrays (scikit-learn models contain arrays)
  - joblib compression support (reduce cache size by ~70%)
  - joblib is scikit-learn recommended serialization library
  - pickle is standard but slower for large arrays
- Serialization pattern defined:
  ```python
  import joblib
  from pathlib import Path

  # Save model
  cache_path = Path("~/.data-extract/models/tfidf/{corpus_hash}_v1.joblib").expanduser()
  joblib.dump(model, cache_path, compress=3)

  # Load model
  model = joblib.load(cache_path)
  ```
- Compression level: 3 (balance between speed and size)
- **Validation:** Cross-reference with Story 3.5.4 smoke test (joblib validated)
- **UAT Required:** No - Industry standard practice

**AC-3.5.5-4: Versioning Strategy Decision Documented (P0)**
- ADR specifies model versioning approach:
  - **Corpus hash:** SHA-256 hash of training corpus (first 12 chars for filenames)
  - **Model version:** Semantic version embedded in filename (v1, v2, etc.)
  - **Metadata file:** JSON sidecar with full provenance
    ```json
    {
      "model_id": "tfidf_{corpus_hash}_v1",
      "model_type": "TfidfVectorizer",
      "scikit_learn_version": "1.3.2",
      "created_at": "2025-11-20T10:30:00Z",
      "corpus_hash": "abc123def456",
      "corpus_size": 1000,
      "config": {
        "max_features": 1000,
        "ngram_range": [1, 2]
      }
    }
    ```
- Version bump triggers:
  - Training corpus changes (different hash)
  - Configuration changes (max_features, ngram_range, etc.)
  - scikit-learn major version upgrade
- **Validation:** Validate hash collision probability (<1e-10 for 12-char SHA-256 prefix)
- **UAT Required:** Yes - Validate versioning strategy supports reproducibility

**AC-3.5.5-5: Cache Invalidation Strategy Documented (P1)**
- ADR specifies when caches are invalidated:
  - **Automatic invalidation:**
    - Corpus hash mismatch (different training data)
    - scikit-learn major version upgrade (1.x → 2.x)
    - Model version mismatch (config changes)
  - **Manual invalidation:**
    - CLI command: `data-extract cache clear --models`
    - Delete cache directory: `rm -rf ~/.data-extract/models/`
  - **No invalidation:**
    - Minor dependency updates (1.3.0 → 1.3.2) - assume backward compatible
- Cache validation on load:
  ```python
  def load_cached_model(corpus_hash, model_type):
      cache_path = get_cache_path(corpus_hash, model_type)
      if not cache_path.exists():
          return None  # Cache miss

      metadata = load_metadata(cache_path)
      if metadata["scikit_learn_version"] != current_sklearn_version():
          return None  # Version mismatch - invalidate

      return joblib.load(cache_path)
  ```
- **Validation:** Code review of cache validation logic
- **UAT Required:** No - Standard cache invalidation pattern

**AC-3.5.5-6: Performance Targets Documented (P1)**
- ADR specifies acceptable cache performance:
  - **Cache hit load time:** <100ms for typical TF-IDF model (~10MB compressed)
  - **Cache miss train time:** <5 seconds for typical corpus (1000 documents)
  - **Cache size:** <500MB total for typical project (10-20 models)
  - **Compression ratio:** ~70% size reduction with joblib compress=3
- Performance measurement approach:
  - Epic 4 stories will establish baselines with pytest-benchmark
  - Baselines documented in docs/performance-baselines-epic-4.md
- **Validation:** Validate targets are achievable (reference joblib benchmarks)
- **UAT Required:** No - Epic 4 will validate with real workloads

## Acceptance Criteria Trade-offs and Deferrals

**AC-3.5.5-2 Trade-off (User Home vs Project-Local):**
- **Issue:** User home may not be writable in some CI/CD environments
- **Resolution:** Fallback to project-local `.cache/models/` if home not writable
- **Rationale:** Most environments support user home; fallback handles edge cases
- **Documented In:** ADR-012 Cache Location section

**AC-3.5.5-5 Trade-off (Automatic vs Manual Invalidation):**
- **Issue:** Too aggressive invalidation wastes CPU (re-train models), too conservative risks stale caches
- **Resolution:** Invalidate on corpus/version changes (automatic), provide manual clear command
- **Rationale:** Balance between correctness (no stale caches) and efficiency (avoid re-training)
- **Documented In:** ADR-012 Cache Invalidation section

**AC-3.5.5-6 Deferred to Epic 4:**
- **Performance baseline measurement** deferred to Epic 4 stories (not part of ADR)
- **ADR documents targets:** Epic 4 validates targets with real implementations
- **Rationale:** ADR provides guidance; Epic 4 provides validation

## Tasks / Subtasks

### Task 1: Research Existing Patterns (AC: All)
- [ ] Review Story 2.5.2 spaCy caching pattern (lazy load + global cache)
- [ ] Review scikit-learn documentation for model persistence recommendations
- [ ] Review joblib documentation for serialization best practices
- [ ] Research cache location conventions (XDG Base Directory Specification for Linux)
- [ ] Research cache invalidation strategies (ETags, version hashes, timestamps)

### Task 2: Create ADR-012 Document Structure (AC: #3.5.5-1)
- [ ] Create `docs/architecture-decisions/` directory if not exists
- [ ] Create `ADR-012-model-caching-strategy.md`
- [ ] Add ADR header:
  - Title: "ADR-012: Model Caching Strategy for Semantic Analysis"
  - Status: Proposed → Accepted (after team review)
  - Date: 2025-11-16 (Epic 3.5 prep sprint)
  - Authors: Winston, Charlie
  - Supersedes: None
  - Superseded by: None
- [ ] Add standard sections: Context, Decision, Consequences, Alternatives Considered

### Task 3: Write Context Section (AC: #3.5.5-1)
- [ ] Explain Epic 4 semantic analysis requirements (TF-IDF, LSA, similarity)
- [ ] Explain why caching is needed (model training is expensive)
- [ ] Reference spaCy caching precedent from Story 2.5.2
- [ ] Reference provenance requirements (source_hash, version tracking)
- [ ] Explain performance targets (<100ms load time for models)

### Task 4: Write Decision Section - Cache Location (AC: #3.5.5-2)
- [ ] Document primary cache location: `~/.data-extract/models/`
- [ ] Document fallback location: `.cache/models/` (project-local)
- [ ] Document environment override: `DATA_EXTRACT_MODEL_CACHE`
- [ ] Document cache directory structure (tfidf/, lsa/, metadata/)
- [ ] Include rationale for each decision

### Task 5: Write Decision Section - Serialization Format (AC: #3.5.5-3)
- [ ] Document serialization library: joblib (not pickle or custom)
- [ ] Document compression level: 3 (balance speed/size)
- [ ] Include code example for save/load pattern
- [ ] Document rationale (joblib optimized for numpy arrays)
- [ ] Reference scikit-learn documentation recommendation

### Task 6: Write Decision Section - Versioning Strategy (AC: #3.5.5-4)
- [ ] Document corpus hash approach (SHA-256, first 12 chars)
- [ ] Document model version approach (semantic versioning in filename)
- [ ] Document metadata JSON sidecar structure
- [ ] Include example metadata file
- [ ] Document version bump triggers (corpus change, config change, major upgrade)

### Task 7: Write Decision Section - Cache Invalidation (AC: #3.5.5-5)
- [ ] Document automatic invalidation triggers (hash mismatch, version mismatch)
- [ ] Document manual invalidation commands (CLI, directory delete)
- [ ] Document cache validation logic (check on load)
- [ ] Include code example for cache validation
- [ ] Document no-invalidation cases (minor dependency updates)

### Task 8: Write Decision Section - Performance Targets (AC: #3.5.5-6)
- [ ] Document cache hit load time target (<100ms)
- [ ] Document cache miss train time target (<5 seconds)
- [ ] Document cache size target (<500MB total)
- [ ] Document compression ratio target (~70% size reduction)
- [ ] Note Epic 4 will establish baselines with pytest-benchmark

### Task 9: Write Consequences Section (AC: #3.5.5-1)
- [ ] Document positive consequences:
  - Consistent model caching across Epic 4 stories
  - Faster semantic analysis (cache hits avoid re-training)
  - Reproducible results (versioning + provenance)
  - Cross-project model reuse (user home cache)
- [ ] Document negative consequences:
  - Cache directory management overhead (invalidation, cleanup)
  - Disk space usage (~500MB for typical project)
  - Complexity of cache validation logic

### Task 10: Write Alternatives Considered Section (AC: #3.5.5-1)
- [ ] Alternative 1: No caching (re-train every time)
  - Rejected: Too slow (5+ seconds per run)
- [ ] Alternative 2: In-memory only caching
  - Rejected: Doesn't persist across runs, wastes CPU
- [ ] Alternative 3: Project-local only (no user home)
  - Rejected: No cross-project reuse, wastes disk space
- [ ] Alternative 4: Database-backed caching (SQLite, Redis)
  - Rejected: Overkill for simple key-value storage, adds dependency
- [ ] Alternative 5: pickle serialization
  - Rejected: Slower than joblib for numpy arrays

### Task 11: Update docs/architecture.md (AC: #3.5.5-1)
- [ ] Open `docs/architecture.md`
- [ ] Locate "## Key Architecture Decisions" section
- [ ] Add ADR-012 to list:
  - **ADR-012:** Model caching strategy for semantic analysis (joblib, user home cache)
- [ ] Save file

### Task 12: Quality Gates and UAT
- [ ] Manual review of ADR-012 completeness (all sections present)
- [ ] Spell check and grammar review
- [ ] Validate code examples are syntactically correct
- [ ] Validate directory structure works on Windows/Linux/macOS
- [ ] UAT: Architecture review with Winston and Charlie (AC-3.5.5-1)
- [ ] UAT: Validate directory structure makes sense (AC-3.5.5-2)
- [ ] UAT: Validate versioning supports reproducibility (AC-3.5.5-4)
- [ ] Update ADR status from Proposed to Accepted after team approval

## Dev Notes

**Provenance Tracking:**
- ADR-012 is an architecture document (no source_hash needed)
- Document includes "Date: 2025-11-16" timestamp
- Reference Epic 3.5, Story 3.5.5 in document header

**Structured Logging:**
- No structured logging needed (architecture documentation, not code)
- Git commit message should reference Story 3.5.5 and Epic 3.5

**Pipeline Wiring:**
- ADR-012 guides Epic 4 implementation (not directly wired into pipeline)
- Epic 4 stories will implement caching according to ADR-012 decisions
- Integration point: src/data_extract/semantic/ module caching logic

**Quality Gates:**
- No code quality gates (markdown documentation)
- Manual review for:
  - ADR template compliance (Context, Decision, Consequences, Alternatives)
  - Technical accuracy (joblib usage, cache paths, versioning)
  - Clarity and completeness (team can follow decisions)

**ADR Template Structure:**
```markdown
# ADR-012: Model Caching Strategy for Semantic Analysis

**Status:** Accepted
**Date:** 2025-11-16
**Authors:** Winston, Charlie
**Epic:** 3.5 (Bridge Epic - Tooling & Semantic Prep)

## Context
[Why we need this decision, Epic 4 requirements, performance targets]

## Decision
[Specific caching strategy decisions: location, serialization, versioning, invalidation, performance]

## Consequences
[Positive and negative outcomes of this decision]

## Alternatives Considered
[Other options evaluated and why rejected]

## References
- Story 2.5.2: spaCy caching pattern
- Story 3.5.4: Semantic dependencies (joblib validation)
- scikit-learn documentation: Model persistence
- joblib documentation: Serialization best practices
```

**spaCy Caching Precedent (Story 2.5.2):**
- **Pattern:** Lazy load + global cache + singleton
- **Location:** spaCy models in `~/.spacy/` (downloaded once, reused)
- **Version tracking:** Model version in metadata (en_core_web_md 3.7.1)
- **Lesson:** User home cache works well for cross-project reuse

**Cache Path Examples:**
```
~/.data-extract/models/tfidf/abc123def456_v1.joblib
~/.data-extract/models/tfidf/abc123def456_v1.json  (metadata)
~/.data-extract/models/lsa/abc123def456_5comp_v1.joblib
~/.data-extract/models/lsa/abc123def456_5comp_v1.json  (metadata)
```

**Corpus Hash Calculation:**
```python
import hashlib

def compute_corpus_hash(documents: List[str]) -> str:
    """Compute deterministic hash for corpus of documents."""
    corpus_str = "\n".join(sorted(documents))  # Sort for determinism
    hash_obj = hashlib.sha256(corpus_str.encode("utf-8"))
    return hash_obj.hexdigest()[:12]  # First 12 chars (48 bits)
```

**Metadata JSON Example:**
```json
{
  "model_id": "tfidf_abc123def456_v1",
  "model_type": "TfidfVectorizer",
  "scikit_learn_version": "1.3.2",
  "created_at": "2025-11-20T10:30:00Z",
  "corpus_hash": "abc123def456",
  "corpus_size": 1000,
  "config": {
    "max_features": 1000,
    "min_df": 2,
    "max_df": 0.95,
    "ngram_range": [1, 2],
    "use_idf": true,
    "smooth_idf": true,
    "sublinear_tf": false
  },
  "vocabulary_size": 850,
  "provenance": {
    "source_files": ["audit_report_2025.pdf", "risk_matrix.xlsx"],
    "epic": "4.1",
    "story": "4.1.1"
  }
}
```

**Performance Targets Justification:**
- **<100ms load time:** joblib loads ~10MB compressed model in ~50ms on SSD
- **<5 seconds train time:** scikit-learn TF-IDF trains 1000 docs in ~2-3 seconds
- **<500MB total cache:** 10-20 models × 10-25MB each = 200-500MB (reasonable)
- **~70% compression:** joblib compress=3 reduces 35MB → 10MB (typical for TF-IDF)

**Cache Invalidation Decision Matrix:**

| Scenario | Invalidate? | Rationale |
|----------|-------------|-----------|
| Corpus hash change | Yes | Training data different → new model needed |
| Config change (max_features) | Yes | Model behavior changes → new version |
| scikit-learn 1.3.0 → 1.3.2 | No | Patch update, assume backward compatible |
| scikit-learn 1.x → 2.x | Yes | Major version, likely breaking changes |
| Manual `cache clear` | Yes | User-requested, always honor |
| Cache older than 30 days | No | Age-based invalidation adds complexity, not needed |

**Alternatives Considered - Detailed:**

1. **No caching (re-train every time):**
   - Pro: Simple, no cache management overhead
   - Con: 5+ seconds per run (unacceptable for UX)
   - Rejected: Performance requirement not met

2. **In-memory only caching:**
   - Pro: Fast access, no disk I/O
   - Con: Lost across runs, wastes CPU re-training
   - Rejected: Doesn't persist, no benefit for typical usage

3. **Project-local only (`.cache/models/`):**
   - Pro: Simple, all files in project directory
   - Con: No cross-project reuse, duplicate cache per project
   - Rejected: Wastes disk space, violates DRY

4. **Database-backed caching (SQLite, Redis):**
   - Pro: Queryable, transactional, supports complex invalidation
   - Con: Overkill for simple key-value, adds dependency
   - Rejected: joblib files are simpler and sufficient

5. **pickle serialization:**
   - Pro: Python standard library, no extra dependency
   - Con: Slower than joblib for large numpy arrays
   - Rejected: joblib is scikit-learn recommended, faster

**Retrospective Learnings Applied:**
- This story directly addresses "Model/Cache ADR (Owner: Winston, Est: 4h)" (Epic 3 retro prep task)
- Prevents Epic 4 mid-story architecture debates (decisions documented upfront)
- Follows spaCy caching precedent from Story 2.5.2 (proven pattern)
- Uses ADR format for institutional memory (Epic 2 retrospective learning)

**Next Story Dependencies:**
- Story 3.5.6 (Semantic QA fixtures) may reference caching strategy for fixture generation
- Story 3.5.7 (TF-IDF/LSA playbook) will reference ADR-012 for implementation guidance
- Epic 4 stories will implement caching according to ADR-012 decisions
