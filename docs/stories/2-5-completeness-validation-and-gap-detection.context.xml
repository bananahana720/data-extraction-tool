<story-context id="bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>2</epicId>
    <storyId>5</storyId>
    <title>Completeness Validation and Gap Detection</title>
    <status>drafted</status>
    <generatedAt>2025-11-11</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>C:\Users\Andrew\projects\data-extraction-tool-1\docs\stories\2-5-completeness-validation-and-gap-detection.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>an audit professional</asA>
    <iWant>to detect and flag incomplete extractions or missing content</iWant>
    <soThat>I can trust all critical information is captured (no silent data loss)</soThat>
    <tasks>
- Task 1: Extend data models for completeness validation (AC: #2.5.3, #2.5.7)
- Task 2: Implement missing images detection (AC: #2.5.1, #2.5.4)
- Task 3: Implement complex objects detection (AC: #2.5.2, #2.5.4)
- Task 4: Implement completeness ratio calculation (AC: #2.5.3)
- Task 5: Implement gap logging with locations (AC: #2.5.4, #2.5.6)
- Task 6: Implement no-silent-failures principle (AC: #2.5.5)
- Task 7: Integrate completeness validation into Normalizer pipeline (AC: all)
- Task 8: Comprehensive testing and quality gates (AC: all)
- Task 9: Documentation and completion
    </tasks>
  </story>

  <acceptanceCriteria>
1. **AC-2.5.1:** Images without alt text are detected and flagged (`QualityFlag.MISSING_IMAGES`)
2. **AC-2.5.2:** Complex objects that can't be extracted are reported (OLE objects, charts, diagrams)
3. **AC-2.5.3:** Extraction completeness ratio is calculated (`extracted_elements / total_elements`)
4. **AC-2.5.4:** Content gaps are logged with specific locations (page number, section name)
5. **AC-2.5.5:** No silent failures occur - all issues are surfaced in validation report
6. **AC-2.5.6:** Validation report identifies what was skipped and why (actionable explanations)
7. **AC-2.5.7:** Flagged documents are marked in output metadata (`QualityFlag` enum values)
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>docs/tech-spec-epic-2.md</path>
        <title>Epic 2 Technical Specification</title>
        <section>Story 2.5: Completeness Validation and Gap Detection</section>
        <snippet>
Detect extraction gaps (missing images without alt text, complex objects like OLE/charts/diagrams that can't be extracted).
Calculate completeness ratio (extracted_elements / total_elements) with 90% threshold.
Zero silent failures—all gaps logged with actionable suggestions and specific locations (page, section).
Validation report includes completeness_passed, missing_images_count, complex_objects_count, extraction_gaps list.
        </snippet>
      </doc>
      <doc>
        <path>docs/architecture.md</path>
        <title>Architecture Documentation</title>
        <section>Quality Validation and Error Handling</section>
        <snippet>
ADR-006: Continue-on-Error pattern - raise ValidationError (recoverable) for validation failures, continue batch processing on single document failures.
Quality validation integrated at Step 7 in normalization pipeline.
NFR-R2: Graceful Degradation - no silent failures, flag problems rather than silently drop content.
        </snippet>
      </doc>
      <doc>
        <path>docs/PRD.md</path>
        <title>Product Requirements Document</title>
        <section>FR-1.3: Completeness Validation, FR-4.2: Quality Flagging</section>
        <snippet>
Ensure no silent data loss during extraction. Quality flagging must automatically identify and flag low-quality chunks.
All issues must be surfaced - no silent quality failures. Validation reporting with summary statistics and actionable recommendations.
        </snippet>
      </doc>
      <doc>
        <path>docs/stories/2-4-ocr-confidence-scoring-and-validation.md</path>
        <title>Story 2.4 - OCR Confidence Validation (Previous Story)</title>
        <section>Learnings and Established Patterns</section>
        <snippet>
QualityValidator class established at src/data_extract/normalize/validation.py (592 lines).
ValidationReport model with quarantine_recommended, quality_flags, extraction_gaps fields.
QualityFlag enum with MISSING_IMAGES, INCOMPLETE_EXTRACTION values.
PipelineStage protocol integration at Step 4 in Normalizer.
        </snippet>
      </doc>
    </docs>
    <code>
      <artifact>
        <path>src/data_extract/core/models.py</path>
        <kind>data_models</kind>
        <symbol>Metadata</symbol>
        <lines>122-170</lines>
        <reason>Add completeness_ratio field (Optional[float], 0.0-1.0 range with validation)</reason>
      </artifact>
      <artifact>
        <path>src/data_extract/core/models.py</path>
        <kind>enum</kind>
        <symbol>QualityFlag</symbol>
        <lines>69-84</lines>
        <reason>Extend with COMPLEX_OBJECTS flag for detection of OLE objects, charts, diagrams</reason>
      </artifact>
      <artifact>
        <path>src/data_extract/core/models.py</path>
        <kind>data_models</kind>
        <symbol>ValidationReport</symbol>
        <lines>235-265</lines>
        <reason>Extend with completeness_passed, missing_images_count, complex_objects_count fields</reason>
      </artifact>
      <artifact>
        <path>src/data_extract/normalize/validation.py</path>
        <kind>service_class</kind>
        <symbol>QualityValidator</symbol>
        <lines>34-592</lines>
        <reason>EXTEND this class with completeness methods: detect_missing_images(), detect_complex_objects(), calculate_completeness_ratio()</reason>
      </artifact>
      <artifact>
        <path>src/data_extract/normalize/config.py</path>
        <kind>config_model</kind>
        <symbol>NormalizationConfig</symbol>
        <lines>23-121</lines>
        <reason>Add completeness_threshold field (float, default 0.90, range 0.0-1.0)</reason>
      </artifact>
      <artifact>
        <path>src/data_extract/normalize/normalizer.py</path>
        <kind>orchestrator</kind>
        <symbol>Normalizer</symbol>
        <lines>1-400</lines>
        <reason>QualityValidator already integrated at Step 4. Ensure completeness validation methods are called in process()</reason>
      </artifact>
      <artifact>
        <path>tests/unit/core/test_models.py</path>
        <kind>test</kind>
        <symbol>TestMetadata, TestValidationReport, TestQualityFlag</symbol>
        <lines>all</lines>
        <reason>Add 15+ tests for new completeness fields in Metadata and ValidationReport</reason>
      </artifact>
      <artifact>
        <path>tests/unit/test_normalize/test_validation.py</path>
        <kind>test</kind>
        <symbol>Various test classes</symbol>
        <lines>all</lines>
        <reason>Add 40+ tests for completeness validation methods (missing images, complex objects, ratio calculation, gap logging)</reason>
      </artifact>
    </code>
    <dependencies>
      <python version="3.12+">
        <package name="pydantic" version=">=2.0.0,<3.0">Data validation for models - Metadata.completeness_ratio field validation</package>
        <package name="structlog" version=">=24.0.0,<25.0">Structured JSON logging for audit trail - gap logging with file metadata</package>
        <package name="pytesseract" version=">=0.3.10">OCR metadata (already in project from Story 2.4) - used for OCR confidence context</package>
        <package name="Pillow" version=">=10.0.0">Image handling for ContentBlock analysis</package>
        <package name="pytest" version=">=8.0.0,<9.0">Testing framework</package>
        <package name="pytest-cov" version=">=5.0.0,<6.0">Coverage reporting - target >85%</package>
        <package name="black" version=">=24.0.0,<25.0">Code formatting - 100 char lines</package>
        <package name="ruff" version=">=0.6.0,<0.7">Linting - 0 errors required</package>
        <package name="mypy" version=">=1.11.0,<2.0">Type checking - strict mode for src/data_extract/</package>
      </python>
    </dependencies>
  </artifacts>

  <constraints>
    <architectural>
      <constraint>PipelineStage Pattern: QualityValidator implements PipelineStage[Document, Document] protocol - extend existing class from Story 2.4, don't create new validator</constraint>
      <constraint>Data Model Immutability: Use model_copy() when modifying Document or Metadata (frozen dataclasses) - never mutate in-place</constraint>
      <constraint>Error Handling (ADR-006): Raise ValidationError (recoverable) for validation failures, not CriticalError - continue batch processing on single document failures</constraint>
      <constraint>Configuration Cascade: CLI flags > Environment variables (DATA_EXTRACT_COMPLETENESS_THRESHOLD) > YAML config > NormalizationConfig defaults</constraint>
      <constraint>Graceful Degradation: If validation fails (missing source metadata), log warning and continue with partial results - never silently drop documents</constraint>
      <constraint>Logging Pattern: Use structlog with structured JSON fields for audit trail - include file path, metric values, thresholds, actions taken</constraint>
    </architectural>
    <quality>
      <constraint>Testing Standards (CRITICAL): Always run Black/Ruff/Mypy BEFORE marking tasks complete - target >85% coverage initially, aim for 100%</constraint>
      <constraint>Type Safety: Full type hints on all public functions - mypy strict mode for src/data_extract/</constraint>
      <constraint>Code Formatting: Black with 100 char line length, Ruff linting (0 errors), Google-style docstrings</constraint>
      <constraint>Test Organization: Tests mirror src/ structure exactly - use pytest markers for selective execution</constraint>
      <constraint>No Brownfield Regressions: All 1000+ existing tests must still pass after changes</constraint>
    </quality>
    <domain>
      <constraint>Completeness Threshold: 0.90 (90%) by default - configurable via NormalizationConfig.completeness_threshold</constraint>
      <constraint>Quarantine Threshold: <0.85 (85%) triggers quarantine_recommended = True (critical threshold)</constraint>
      <constraint>No Silent Failures: All detected gaps must be logged even if below threshold - nothing silently dropped</constraint>
      <constraint>Audit Trail Required: All validation decisions logged with JSON structure for reproducibility</constraint>
    </domain>
  </constraints>
  <interfaces>
    <interface>
      <name>QualityValidator.detect_missing_images</name>
      <kind>method</kind>
      <signature>def detect_missing_images(self, blocks: List[ContentBlock]) -> List[Dict[str, Any]]</signature>
      <path>src/data_extract/normalize/validation.py</path>
      <description>Analyze ContentBlocks for block_type=='image' with missing/empty alt text. Returns list of extraction gaps with location details.</description>
    </interface>
    <interface>
      <name>QualityValidator.detect_complex_objects</name>
      <kind>method</kind>
      <signature>def detect_complex_objects(self, blocks: List[ContentBlock]) -> List[Dict[str, Any]]</signature>
      <path>src/data_extract/normalize/validation.py</path>
      <description>Detect ContentBlocks with block_type in ['ole_object', 'chart', 'diagram', 'drawing']. Returns list of complex objects with metadata.</description>
    </interface>
    <interface>
      <name>QualityValidator.calculate_completeness_ratio</name>
      <kind>method</kind>
      <signature>def calculate_completeness_ratio(self, extraction_result: ExtractionResult) -> float</signature>
      <path>src/data_extract/normalize/validation.py</path>
      <description>Calculate ratio of extracted elements / total elements with division-by-zero handling. Returns float 0.0-1.0.</description>
    </interface>
    <interface>
      <name>QualityValidator.log_extraction_gap</name>
      <kind>method</kind>
      <signature>def log_extraction_gap(self, gap_type: str, location: Dict[str, Any], description: str, severity: str) -> Dict[str, Any]</signature>
      <path>src/data_extract/normalize/validation.py</path>
      <description>Helper method for structured gap logging with JSON output. Returns gap dictionary for ValidationReport.extraction_gaps list.</description>
    </interface>
    <interface>
      <name>Metadata.completeness_ratio</name>
      <kind>field</kind>
      <signature>completeness_ratio: Optional[float] = Field(None, ge=0.0, le=1.0)</signature>
      <path>src/data_extract/core/models.py</path>
      <description>New field in Metadata model with Pydantic validation for 0.0-1.0 range.</description>
    </interface>
    <interface>
      <name>ValidationReport.completeness_passed</name>
      <kind>field</kind>
      <signature>completeness_passed: bool</signature>
      <path>src/data_extract/core/models.py</path>
      <description>New required field in ValidationReport - True if completeness_ratio >= threshold.</description>
    </interface>
    <interface>
      <name>ValidationReport.missing_images_count</name>
      <kind>field</kind>
      <signature>missing_images_count: int = 0</signature>
      <path>src/data_extract/core/models.py</path>
      <description>New field tracking number of images without alt text detected.</description>
    </interface>
    <interface>
      <name>ValidationReport.complex_objects_count</name>
      <kind>field</kind>
      <signature>complex_objects_count: int = 0</signature>
      <path>src/data_extract/core/models.py</path>
      <description>New field tracking number of complex objects (OLE, charts, diagrams) detected.</description>
    </interface>
    <interface>
      <name>QualityFlag.COMPLEX_OBJECTS</name>
      <kind>enum_value</kind>
      <signature>COMPLEX_OBJECTS = "complex_objects"</signature>
      <path>src/data_extract/core/models.py</path>
      <description>New enum value in QualityFlag for flagging documents with un-extractable complex objects.</description>
    </interface>
    <interface>
      <name>NormalizationConfig.completeness_threshold</name>
      <kind>field</kind>
      <signature>completeness_threshold: float = Field(default=0.90, ge=0.0, le=1.0)</signature>
      <path>src/data_extract/normalize/config.py</path>
      <description>New config field for completeness validation threshold with Pydantic validation.</description>
    </interface>
  </interfaces>
  <tests>
    <standards>
Story 2.5 follows Epic 2 testing standards: >85% coverage target, aim for 100%. All tests must pass Black/Ruff/Mypy before marking tasks complete.

Test organization mirrors src/ structure exactly:
- tests/unit/core/test_models.py - Model extensions (15+ tests)
- tests/unit/test_normalize/test_validation.py - Completeness validation methods (40+ tests)

Use pytest markers: @pytest.mark.unit for unit tests. Test fixtures in tests/conftest.py.

Quality gates: Black formatting (100 char lines), Ruff linting (0 errors), Mypy strict mode (src/data_extract/ only), all tests passing, no brownfield regressions.
    </standards>
    <locations>
      <location>tests/unit/core/test_models.py - Model validation tests for Metadata.completeness_ratio, ValidationReport extensions, QualityFlag.COMPLEX_OBJECTS</location>
      <location>tests/unit/test_normalize/test_validation.py - QualityValidator completeness methods (detect_missing_images, detect_complex_objects, calculate_completeness_ratio, log_extraction_gap)</location>
      <location>tests/integration/ - Optional end-to-end completeness validation tests (low priority)</location>
      <location>tests/fixtures/ - Sample documents with missing images, complex objects, low completeness for test fixtures</location>
    </locations>
    <ideas>
      <test_idea ac="AC-2.5.1">TestMissingImagesDetection: Test image ContentBlocks without alt text are flagged, verify extraction_gaps populated with location details, test no images case, all images with alt text case, mixed case</test_idea>
      <test_idea ac="AC-2.5.2">TestComplexObjectsDetection: Test OLE objects detected, charts detected, diagrams detected, verify complex_objects_count incremented, verify extraction_gaps populated with object metadata</test_idea>
      <test_idea ac="AC-2.5.3">TestCompletenessRatioCalculation: Test 8/10 elements = 0.8 ratio, test 0 total elements (division by zero), test 0 extracted elements, test 100% completeness (10/10), test threshold boundary (exactly 0.90)</test_idea>
      <test_idea ac="AC-2.5.4">TestGapLogging: Test gap log includes page number, section name, gap_type, description, severity. Verify JSON structure with all required fields, test structlog output format</test_idea>
      <test_idea ac="AC-2.5.5">TestNoSilentFailures: Test all detected gaps logged even if below threshold, verify ValidationReport.quarantine_recommended = True if ratio < 0.85, test graceful degradation on validation errors</test_idea>
      <test_idea ac="AC-2.5.6">TestValidationReportGeneration: Test actionable descriptions in extraction_gaps, verify what/why explanations clear, test report includes suggested_action field for each gap</test_idea>
      <test_idea ac="AC-2.5.7">TestMetadataEnrichment: Test QualityFlag enum values added to Metadata.quality_flags list, test completeness_ratio field populated, verify flags propagate to output metadata</test_idea>
      <test_idea ac="Integration">TestCompletenessValidationPipeline: Full Extract → Normalize → Validate workflow with document containing gaps, verify all gaps detected and reported, test metadata enriched correctly</test_idea>
    </ideas>
  </tests>
</story-context>
