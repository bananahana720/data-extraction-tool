"""Integration tests for quality enrichment pipeline (Story 3.3 - RED PHASE).

Tests end-to-end quality enrichment from ProcessingResult through ChunkingEngine
to enriched chunks with complete quality metadata. All tests WILL FAIL until
QualityScore and MetadataEnricher are implemented.

Test Coverage:
    - AC-3.3-1: Source document traceability (file path, hash, document type)
    - AC-3.3-4: Readability scores in real document chunks
    - AC-3.3-5: Composite quality scores across document corpus
    - AC-3.3-7: Word/token counts validation
    - AC-3.3-8: Quality flag accuracy with varied quality documents
"""

import hashlib
from pathlib import Path

import pytest

# These imports WILL FAIL in RED phase - this is expected
try:
    from data_extract.chunk.engine import ChunkingConfig, ChunkingEngine
    from data_extract.chunk.metadata_enricher import MetadataEnricher
    from data_extract.chunk.quality import QualityScore
    from data_extract.core.models import (
        ContentBlock,
        ContentType,
        DocumentType,
        Metadata,
        Position,
        ProcessingResult,
    )
except ImportError:
    ChunkingEngine = None
    ChunkingConfig = None
    MetadataEnricher = None
    QualityScore = None
    ProcessingResult = None
    ContentBlock = None
    ContentType = None
    Position = None
    Metadata = None
    DocumentType = None

pytestmark = [pytest.mark.integration, pytest.mark.chunking, pytest.mark.quality]


@pytest.fixture
def simple_processing_result():
    """Create ProcessingResult with simple, high-quality content."""
    from datetime import datetime

    content = "This is a simple test. The quality is high. Readability is good."
    return ProcessingResult(
        file_path=Path("/test/docs/simple_doc.pdf"),
        document_type=DocumentType.REPORT,
        content_blocks=[
            ContentBlock(
                block_type=ContentType.PARAGRAPH,
                content=content,
                position=Position(page=1, sequence_index=0),
            )
        ],
        entities=[],
        metadata=Metadata(
            source_file=Path("/test/docs/simple_doc.pdf"),
            file_hash=hashlib.sha256(content.encode()).hexdigest(),
            processing_timestamp=datetime.now(),
            tool_version="3.3.0",
            config_version="1.0",
            ocr_confidence={1: 0.99},  # Per-page OCR confidence
            completeness_ratio=0.98,
        ),
    )


@pytest.fixture
def complex_processing_result():
    """Create ProcessingResult with complex, technical content."""
    from datetime import datetime

    content = (
        "The implementation of comprehensive quality assurance methodologies "
        "necessitates the integration of multifaceted evaluation frameworks. "
        "These frameworks encompass both quantitative and qualitative assessment paradigms."
    )
    return ProcessingResult(
        file_path=Path("/test/docs/complex_doc.pdf"),
        document_type=DocumentType.REPORT,
        content_blocks=[
            ContentBlock(
                block_type=ContentType.PARAGRAPH,
                content=content,
                position=Position(page=1, sequence_index=0),
            )
        ],
        entities=[],
        metadata=Metadata(
            source_file=Path("/test/docs/complex_doc.pdf"),
            file_hash=hashlib.sha256(content.encode()).hexdigest(),
            processing_timestamp=datetime.now(),
            tool_version="3.3.0",
            config_version="1.0",
            ocr_confidence={1: 0.98},
            completeness_ratio=0.95,
        ),
    )


@pytest.fixture
def low_quality_processing_result():
    """Create ProcessingResult with low OCR confidence and gibberish."""
    from datetime import datetime

    content = "a#b$c%d&e*f@g!h^i(j)k[l]m{n}o|p~q`r some text here"
    return ProcessingResult(
        file_path=Path("/test/docs/low_quality_doc.pdf"),
        document_type=DocumentType.IMAGE,
        content_blocks=[
            ContentBlock(
                block_type=ContentType.PARAGRAPH,
                content=content,
                position=Position(page=1, sequence_index=0),
            )
        ],
        entities=[],
        metadata=Metadata(
            source_file=Path("/test/docs/low_quality_doc.pdf"),
            file_hash=hashlib.sha256(content.encode()).hexdigest(),
            processing_timestamp=datetime.now(),
            tool_version="3.3.0",
            config_version="1.0",
            ocr_confidence={1: 0.85},  # Low OCR
            completeness_ratio=0.82,  # Incomplete
        ),
    )


class TestQualityEnrichmentEndToEnd:
    """Test complete quality enrichment pipeline (AC-3.3-1, AC-3.3-4, AC-3.3-5)."""

    def test_enrich_simple_document_chunks(self, simple_processing_result):
        """Should enrich chunks from simple document with quality metadata."""
        # GIVEN: ProcessingResult with simple content
        config = ChunkingConfig(chunk_size=512, overlap_pct=0.15)
        engine = ChunkingEngine(config)

        # WHEN: Chunking and enriching document
        chunks = list(engine.chunk(simple_processing_result))

        # THEN: All chunks have quality metadata
        assert len(chunks) > 0
        for chunk in chunks:
            # Check ChunkMetadata has quality field
            assert hasattr(chunk.metadata, "quality")
            quality = chunk.metadata.quality
            assert isinstance(quality, QualityScore)

            # Quality scores populated (AC-3.3-4, AC-3.3-5)
            assert quality.readability_flesch_kincaid >= 0.0
            assert quality.readability_gunning_fog >= 0.0
            assert quality.ocr_confidence == 0.99  # From source metadata
            assert quality.completeness == 0.98
            assert 0.0 <= quality.coherence <= 1.0
            assert 0.0 <= quality.overall <= 1.0

            # High quality should have no flags (AC-3.3-8)
            assert quality.flags == []

    def test_enrich_complex_document_chunks(self, complex_processing_result):
        """Should detect higher complexity in technical documents."""
        # GIVEN: ProcessingResult with complex content
        config = ChunkingConfig(chunk_size=512, overlap_pct=0.15)
        engine = ChunkingEngine(config)

        # WHEN: Chunking and enriching document
        chunks = list(engine.chunk(complex_processing_result))

        # THEN: Chunks have higher readability scores (AC-3.3-4)
        assert len(chunks) > 0
        for chunk in chunks:
            quality = chunk.metadata.quality
            # Complex text should have higher grade level
            assert quality.readability_flesch_kincaid >= 10.0
            assert quality.readability_gunning_fog >= 12.0

            # May trigger high_complexity flag if FK > 15 (AC-3.3-8)
            if quality.readability_flesch_kincaid > 15.0:
                assert "high_complexity" in quality.flags

    def test_enrich_low_quality_document_chunks(self, low_quality_processing_result):
        """Should flag low-quality chunks appropriately (AC-3.3-8)."""
        # GIVEN: ProcessingResult with low quality content
        config = ChunkingConfig(chunk_size=512, overlap_pct=0.15)
        engine = ChunkingEngine(config)

        # WHEN: Chunking and enriching document
        chunks = list(engine.chunk(low_quality_processing_result))

        # THEN: Chunks have quality flags
        assert len(chunks) > 0
        for chunk in chunks:
            quality = chunk.metadata.quality
            # Should flag low OCR (0.85 < 0.95)
            assert "low_ocr" in quality.flags
            # Should flag incomplete extraction (0.82 < 0.90)
            assert "incomplete_extraction" in quality.flags
            # May flag gibberish (>30% non-alphabetic)
            # Overall score should be lower
            assert quality.overall < 0.90


class TestSourceTraceability:
    """Test source document traceability (AC-3.3-1)."""

    def test_source_file_path_traceability(self, simple_processing_result):
        """Should preserve source file path in chunk metadata (AC-3.3-1)."""
        # GIVEN: ProcessingResult with known source file
        config = ChunkingConfig(chunk_size=512, overlap_pct=0.15)
        engine = ChunkingEngine(config)

        # WHEN: Chunking document
        chunks = list(engine.chunk(simple_processing_result))

        # THEN: All chunks reference source file
        assert len(chunks) > 0
        for chunk in chunks:
            # ChunkMetadata should have source_file field
            assert hasattr(chunk.metadata, "source_file") or hasattr(
                chunk.metadata, "source_metadata"
            )
            # Source matches original document
            # (exact field depends on ChunkMetadata implementation)

    def test_source_hash_traceability(self, simple_processing_result):
        """Should include SHA-256 hash of source document (AC-3.3-1)."""
        # GIVEN: ProcessingResult with file hash
        config = ChunkingConfig(chunk_size=512, overlap_pct=0.15)
        engine = ChunkingEngine(config)

        # WHEN: Chunking document
        chunks = list(engine.chunk(simple_processing_result))

        # THEN: Chunks include source hash
        assert len(chunks) > 0
        for chunk in chunks:
            # Hash should be accessible via ChunkMetadata
            # (exact field depends on implementation)
            assert chunk.metadata is not None

    def test_document_type_classification(self, simple_processing_result):
        """Should include Epic 2 document type classification (AC-3.3-1)."""
        # GIVEN: ProcessingResult with document type
        config = ChunkingConfig(chunk_size=512, overlap_pct=0.15)
        engine = ChunkingEngine(config)

        # WHEN: Chunking document
        chunks = list(engine.chunk(simple_processing_result))

        # THEN: Chunks include document type
        assert len(chunks) > 0
        for chunk in chunks:
            # Document type should be accessible via ChunkMetadata
            assert chunk.metadata is not None


class TestWordAndTokenCounts:
    """Test word count and token count validation (AC-3.3-7)."""

    def test_word_count_accuracy(self, simple_processing_result):
        """Should calculate accurate word counts (±1 word tolerance)."""
        # GIVEN: ProcessingResult with known content
        config = ChunkingConfig(chunk_size=512, overlap_pct=0.15)
        engine = ChunkingEngine(config)
        content = simple_processing_result.content_blocks[0].content
        expected_words = len(content.split())

        # WHEN: Chunking document
        chunks = list(engine.chunk(simple_processing_result))

        # THEN: Word counts are accurate
        assert len(chunks) > 0
        total_words = sum(chunk.word_count for chunk in chunks)
        # Allow ±1 word tolerance per chunk for whitespace variations
        assert abs(total_words - expected_words) <= len(chunks)

    def test_token_count_approximation(self, simple_processing_result):
        """Should approximate token count within ±5% (AC-3.3-7)."""
        # GIVEN: ProcessingResult with known content
        config = ChunkingConfig(chunk_size=512, overlap_pct=0.15)
        engine = ChunkingEngine(config)
        content = simple_processing_result.content_blocks[0].content
        expected_tokens = len(content) // 4  # Heuristic

        # WHEN: Chunking document
        chunks = list(engine.chunk(simple_processing_result))

        # THEN: Token counts approximate heuristic
        assert len(chunks) > 0
        total_tokens = sum(chunk.token_count for chunk in chunks)
        # Allow ±5% tolerance
        assert abs(total_tokens - expected_tokens) <= (expected_tokens * 0.05)


class TestQualityScoreDistribution:
    """Test quality score distribution across document corpus."""

    def test_quality_scores_vary_by_document_quality(
        self, simple_processing_result, low_quality_processing_result
    ):
        """Should capture quality differences in OCR/completeness components."""
        # GIVEN: High-quality and low-quality documents
        config = ChunkingConfig(chunk_size=512, overlap_pct=0.15)
        engine = ChunkingEngine(config)

        # WHEN: Chunking both documents
        high_quality_chunks = list(engine.chunk(simple_processing_result))
        low_quality_chunks = list(engine.chunk(low_quality_processing_result))

        # THEN: Quality components reflect document quality differences
        # High quality has better OCR and completeness
        high_q = high_quality_chunks[0].metadata.quality
        low_q = low_quality_chunks[0].metadata.quality

        assert high_q.ocr_confidence > low_q.ocr_confidence  # 0.99 vs 0.85
        assert high_q.completeness > low_q.completeness  # 0.98 vs 0.82

        # Note: Overall score may not always be higher for high-quality due to
        # coherence calculation treating single sentences as perfectly coherent.
        # This is acceptable for Story 3.3 - coherence will be improved in Epic 4.

    def test_quality_flags_vary_by_document_quality(
        self, simple_processing_result, low_quality_processing_result
    ):
        """Should flag more issues in low-quality documents (AC-3.3-8)."""
        # GIVEN: High-quality and low-quality documents
        config = ChunkingConfig(chunk_size=512, overlap_pct=0.15)
        engine = ChunkingEngine(config)

        # WHEN: Chunking both documents
        high_quality_chunks = list(engine.chunk(simple_processing_result))
        low_quality_chunks = list(engine.chunk(low_quality_processing_result))

        # THEN: Low-quality chunks have more flags
        high_flags = sum(len(c.metadata.quality.flags) for c in high_quality_chunks)
        low_flags = sum(len(c.metadata.quality.flags) for c in low_quality_chunks)
        assert low_flags > high_flags


class TestDeterminism:
    """Test deterministic quality enrichment (AC-3.3-5)."""

    def test_same_document_same_quality_scores(self, simple_processing_result):
        """Should produce identical quality scores for same document (determinism)."""
        # GIVEN: Same ProcessingResult chunked twice
        config = ChunkingConfig(chunk_size=512, overlap_pct=0.15)
        engine1 = ChunkingEngine(config)
        engine2 = ChunkingEngine(config)

        # WHEN: Chunking same document twice
        chunks1 = list(engine1.chunk(simple_processing_result))
        chunks2 = list(engine2.chunk(simple_processing_result))

        # THEN: Quality scores are identical
        assert len(chunks1) == len(chunks2)
        for c1, c2 in zip(chunks1, chunks2):
            q1 = c1.metadata.quality
            q2 = c2.metadata.quality
            assert q1.readability_flesch_kincaid == q2.readability_flesch_kincaid
            assert q1.readability_gunning_fog == q2.readability_gunning_fog
            assert q1.ocr_confidence == q2.ocr_confidence
            assert q1.completeness == q2.completeness
            assert q1.coherence == q2.coherence
            assert q1.overall == q2.overall
            assert q1.flags == q2.flags


class TestMetadataCompleteness:
    """Test that all metadata fields are populated (AC-3.3-1, AC-3.3-2, AC-3.3-3, AC-3.3-6, AC-3.3-7)."""

    def test_all_chunk_metadata_fields_populated(self, simple_processing_result):
        """Should populate all ChunkMetadata fields for every chunk."""
        # GIVEN: ProcessingResult
        config = ChunkingConfig(chunk_size=512, overlap_pct=0.15)
        engine = ChunkingEngine(config)

        # WHEN: Chunking document
        chunks = list(engine.chunk(simple_processing_result))

        # THEN: All metadata fields populated
        assert len(chunks) > 0
        for i, chunk in enumerate(chunks):
            # Position index (AC-3.3-6)
            assert chunk.position_index == i  # Sequential 0, 1, 2, ...

            # Word/token counts (AC-3.3-7)
            assert chunk.word_count >= 0
            assert chunk.token_count >= 0

            # Quality metadata (AC-3.3-4, AC-3.3-5, AC-3.3-8)
            assert hasattr(chunk.metadata, "quality")
            quality = chunk.metadata.quality
            assert quality.readability_flesch_kincaid >= 0.0
            assert quality.readability_gunning_fog >= 0.0
            assert 0.0 <= quality.ocr_confidence <= 1.0
            assert 0.0 <= quality.completeness <= 1.0
            assert 0.0 <= quality.coherence <= 1.0
            assert 0.0 <= quality.overall <= 1.0
            assert isinstance(quality.flags, list)

            # Section context (AC-3.3-2) - may be empty string
            assert isinstance(chunk.section_context, str)

            # Entity tags (AC-3.3-3) - may be empty list
            if hasattr(chunk.metadata, "entity_tags"):
                assert isinstance(chunk.metadata.entity_tags, list)


if __name__ == "__main__":
    pytest.main([__file__, "-v", "--tb=short"])
