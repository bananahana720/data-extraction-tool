"""BT-002: Cluster Coherence Validation Test.

This behavioral test validates that LSA-based clustering produces coherent topic
groups where related audit documents cluster together.
"""

from pathlib import Path
from typing import Dict, List

import numpy as np
import pytest
import yaml
from sklearn.cluster import KMeans
from sklearn.decomposition import TruncatedSVD
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import silhouette_score
from sklearn.pipeline import Pipeline

pytestmark = [pytest.mark.behavioral, pytest.mark.semantic, pytest.mark.epic4]


class LSAProcessor:
    """Latent Semantic Analysis processor for document dimensionality reduction."""

    def __init__(self, n_components: int = 100):
        """Initialize the LSA processor.

        Args:
            n_components: Number of LSA components (topics) to extract.
        """
        self.n_components = n_components
        self.vectorizer = TfidfVectorizer(
            max_features=5000,
            stop_words="english",
            ngram_range=(1, 2),
            min_df=2,
            max_df=0.95,
            use_idf=True,
        )
        self.svd = TruncatedSVD(n_components=n_components, random_state=42)
        self.pipeline = None

    def fit_transform(self, documents: List[str]) -> np.ndarray:
        """Fit LSA model and transform documents to semantic space.

        Args:
            documents: List of document texts.

        Returns:
            Document vectors in LSA semantic space.
        """
        # Create processing pipeline
        self.pipeline = Pipeline([("tfidf", self.vectorizer), ("lsa", self.svd)])

        # Fit and transform
        lsa_vectors = self.pipeline.fit_transform(documents)
        return lsa_vectors

    def get_explained_variance(self) -> float:
        """Get the cumulative explained variance ratio.

        Returns:
            Cumulative explained variance ratio.
        """
        if self.svd.explained_variance_ratio_ is not None:
            return np.sum(self.svd.explained_variance_ratio_)
        return 0.0


class DocumentClusterer:
    """Document clustering using K-means on LSA vectors."""

    def __init__(self, n_clusters: int = 10):
        """Initialize the document clusterer.

        Args:
            n_clusters: Number of clusters to create.
        """
        self.n_clusters = n_clusters
        self.kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10, max_iter=300)
        self.cluster_labels_ = None

    def fit_predict(self, vectors: np.ndarray) -> np.ndarray:
        """Fit clustering model and predict cluster labels.

        Args:
            vectors: Document vectors (from LSA).

        Returns:
            Cluster labels for each document.
        """
        self.cluster_labels_ = self.kmeans.fit_predict(vectors)
        return self.cluster_labels_

    def get_cluster_centers(self) -> np.ndarray:
        """Get the cluster center vectors.

        Returns:
            Cluster center vectors.
        """
        return self.kmeans.cluster_centers_


class TestClusterCoherence:
    """Behavioral test for document cluster quality."""

    @pytest.fixture
    def labeled_document_clusters(self) -> Dict[str, Dict]:
        """Load labeled clusters from golden dataset.

        Returns:
            Dictionary of cluster labels and their documents.
        """
        golden_path = Path(__file__).parent.parent.parent / "fixtures/semantic/golden_dataset.yaml"

        with open(golden_path, "r") as f:
            data = yaml.safe_load(f)

        return data["golden_dataset"]["labeled_clusters"]

    @pytest.fixture
    def semantic_corpus_documents(self) -> Dict[str, str]:
        """Generate semantic corpus with labeled documents.

        Returns:
            Dictionary mapping document IDs to content.
        """
        documents = {}

        # IT Security cluster documents
        documents[
            "access_control_policy.txt"
        ] = """
        Access Control Policy and Standards
        This comprehensive policy defines role-based access control (RBAC) requirements.
        Principle of least privilege must be enforced across all systems.
        Multi-factor authentication required for privileged accounts.
        Quarterly access reviews and certification processes mandatory.
        User provisioning and deprovisioning workflows defined.
        """

        documents[
            "password_standards.txt"
        ] = """
        Enterprise Password Standards
        Minimum password length of 14 characters with complexity requirements.
        Password history of 24 passwords enforced. Maximum age 90 days.
        Account lockout after 5 failed attempts within 15 minutes.
        Service accounts require 25+ character passphrases.
        Password managers recommended for all users.
        """

        documents[
            "encryption_guidelines.txt"
        ] = """
        Data Encryption Guidelines and Standards
        AES-256 encryption required for all data at rest.
        TLS 1.3 preferred, TLS 1.2 minimum for data in transit.
        Hardware Security Module (HSM) for key management.
        Annual key rotation mandatory for all encryption keys.
        Encryption algorithm review and updates annually.
        """

        documents[
            "network_security_baseline.txt"
        ] = """
        Network Security Baseline Configuration
        Firewall rules must follow deny-by-default principle.
        Network segmentation required between security zones.
        Intrusion detection and prevention systems mandatory.
        VPN access with certificate-based authentication.
        Continuous network monitoring and alerting.
        """

        documents[
            "vulnerability_assessment_report.txt"
        ] = """
        Vulnerability Assessment and Management
        Monthly vulnerability scanning of all systems.
        Critical vulnerabilities patched within 24 hours.
        High severity within 7 days, Medium within 30 days.
        Penetration testing conducted quarterly.
        Risk acceptance process for unpatched vulnerabilities.
        """

        documents[
            "security_awareness_training.txt"
        ] = """
        Security Awareness Training Program
        Annual mandatory security training for all employees.
        Phishing simulation exercises monthly.
        Role-based security training for privileged users.
        Security awareness metrics and reporting.
        Incident reporting procedures training.
        """

        documents[
            "system_access_reviews.txt"
        ] = """
        System Access Review Procedures
        Quarterly review of all privileged accounts.
        Semi-annual review of standard user access.
        Automated access certification workflows.
        Segregation of duties validation.
        Orphaned account detection and removal.
        """

        documents[
            "penetration_testing_report.txt"
        ] = """
        Penetration Testing Report and Findings
        External and internal penetration tests performed.
        Web application security testing included.
        Social engineering assessment conducted.
        Physical security testing when applicable.
        Remediation tracking and validation.
        """

        documents[
            "security_incident_log.txt"
        ] = """
        Security Incident Management Log
        Incident classification and severity ratings.
        Response time SLAs based on severity.
        Root cause analysis for all incidents.
        Lessons learned documentation.
        Incident metrics and trend analysis.
        """

        documents[
            "firewall_configuration_standard.txt"
        ] = """
        Firewall Configuration Standards
        Stateful inspection firewall requirements.
        Default deny inbound and outbound rules.
        DMZ configuration for public-facing services.
        Logging all denied connection attempts.
        Regular firewall rule reviews and cleanup.
        """

        documents[
            "malware_protection_policy.txt"
        ] = """
        Malware Protection and Prevention Policy
        Endpoint detection and response (EDR) required.
        Real-time anti-malware scanning enabled.
        Email and web content filtering mandatory.
        Sandboxing for suspicious files.
        Regular anti-malware signature updates.
        """

        documents[
            "patch_management_process.txt"
        ] = """
        Patch Management Process and Procedures
        Automated patch deployment where possible.
        Testing in non-production before production.
        Emergency patching procedures defined.
        Patch compliance reporting monthly.
        Exception process for systems that cannot be patched.
        """

        documents[
            "identity_management_policy.txt"
        ] = """
        Identity and Access Management Policy
        Single sign-on (SSO) for enterprise applications.
        Privileged access management (PAM) solution.
        Identity lifecycle management processes.
        Federation standards for third-party access.
        Regular entitlement reviews and cleanup.
        """

        # Financial Controls cluster documents
        documents[
            "sox_compliance_checklist.txt"
        ] = """
        Sarbanes-Oxley Compliance Checklist
        Section 302 CEO/CFO certification requirements.
        Section 404 internal controls assessment.
        Management testing of key controls.
        External auditor testing coordination.
        Deficiency remediation tracking.
        """

        documents[
            "internal_audit_procedures.txt"
        ] = """
        Internal Audit Procedures and Methodology
        Risk-based audit planning approach.
        Annual audit plan development process.
        Audit fieldwork standards and documentation.
        Finding rating and reporting criteria.
        Management action plan tracking.
        """

        documents[
            "financial_reporting_controls.txt"
        ] = """
        Financial Reporting Internal Controls
        Month-end close checklist and timeline.
        Account reconciliation requirements.
        Journal entry approval matrix.
        Financial statement review process.
        Disclosure controls and procedures.
        """

        documents[
            "segregation_of_duties.txt"
        ] = """
        Segregation of Duties Matrix
        Incompatible duties identification.
        Compensating controls where segregation not possible.
        Regular SOD conflict analysis.
        System-enforced SOD rules.
        Periodic SOD violation reviews.
        """

        documents[
            "budget_control_procedures.txt"
        ] = """
        Budget Control and Monitoring Procedures
        Budget preparation and approval process.
        Monthly budget vs actual variance analysis.
        Budget transfer and modification controls.
        Capital expenditure approval limits.
        Operating expense monitoring.
        """

        documents[
            "procurement_controls.txt"
        ] = """
        Procurement and Purchasing Controls
        Purchase requisition approval workflow.
        Vendor selection and due diligence.
        Three-way match for invoices.
        Contract management procedures.
        Procurement card controls.
        """

        documents[
            "fraud_detection_controls.txt"
        ] = """
        Fraud Detection and Prevention Controls
        Fraud risk assessment methodology.
        Anti-fraud controls implementation.
        Whistleblower hotline procedures.
        Investigation protocols.
        Fraud awareness training.
        """

        documents[
            "expense_approval_matrix.txt"
        ] = """
        Expense Approval Authority Matrix
        Approval limits by position level.
        Expense report review procedures.
        Receipt requirements and documentation.
        Travel and entertainment policies.
        Corporate card monitoring.
        """

        documents[
            "journal_entry_controls.txt"
        ] = """
        Journal Entry Controls and Procedures
        Manual journal entry approval requirements.
        Recurring journal entry reviews.
        Supporting documentation standards.
        Post-close journal entry restrictions.
        Journal entry analytics and monitoring.
        """

        documents[
            "reconciliation_procedures.txt"
        ] = """
        Account Reconciliation Procedures
        Balance sheet account reconciliation schedule.
        Bank reconciliation requirements.
        Intercompany reconciliation process.
        Reconciliation review and approval.
        Reconciling item aging and resolution.
        """

        documents[
            "capital_expenditure_controls.txt"
        ] = """
        Capital Expenditure Control Procedures
        CapEx request and approval process.
        Business case requirements.
        Post-implementation reviews.
        Asset capitalization thresholds.
        Depreciation policy compliance.
        """

        # Compliance cluster documents
        documents[
            "gdpr_compliance_guide.txt"
        ] = """
        GDPR Compliance Implementation Guide
        Lawful basis for data processing documentation.
        Privacy by design principles implementation.
        Data subject rights procedures.
        Data breach notification within 72 hours.
        Privacy impact assessments required.
        """

        documents[
            "data_retention_policy.txt"
        ] = """
        Data Retention and Disposal Policy
        Retention schedules by data category.
        Legal and regulatory retention requirements.
        Secure data disposal procedures.
        Retention schedule annual review.
        Hold procedures for litigation.
        """

        documents[
            "privacy_impact_assessment.txt"
        ] = """
        Privacy Impact Assessment Framework
        PIA triggers and thresholds.
        Data flow mapping requirements.
        Risk assessment methodology.
        Mitigation measures documentation.
        PIA approval and review process.
        """

        documents[
            "audit_trail_requirements.txt"
        ] = """
        Audit Trail and Logging Requirements
        System activity logging standards.
        Log retention periods defined.
        Log integrity protection measures.
        Log review and monitoring procedures.
        Audit trail reporting capabilities.
        """

        documents[
            "data_classification_policy.txt"
        ] = """
        Data Classification and Handling Policy
        Classification levels: Public, Internal, Confidential, Restricted.
        Handling requirements per classification.
        Data labeling standards.
        Encryption requirements by class.
        Access controls per classification.
        """

        documents[
            "compliance_monitoring_plan.txt"
        ] = """
        Compliance Monitoring and Testing Plan
        Regulatory requirement tracking.
        Compliance testing schedule.
        Control effectiveness assessment.
        Compliance metrics and KPIs.
        Regulatory change management.
        """

        documents[
            "regulatory_compliance_matrix.txt"
        ] = """
        Regulatory Compliance Requirements Matrix
        Applicable regulations inventory.
        Compliance obligations mapping.
        Control implementation status.
        Compliance gap analysis.
        Remediation planning and tracking.
        """

        documents[
            "third_party_compliance.txt"
        ] = """
        Third Party Compliance Management
        Vendor compliance assessment criteria.
        Due diligence requirements.
        Ongoing monitoring procedures.
        Compliance attestation requirements.
        Non-compliance remediation process.
        """

        documents[
            "data_privacy_requirements.txt"
        ] = """
        Data Privacy Requirements and Standards
        Personal data inventory maintenance.
        Consent management procedures.
        Cross-border data transfer controls.
        Privacy notice requirements.
        Data minimization principles.
        """

        documents[
            "legal_hold_procedures.txt"
        ] = """
        Legal Hold and eDiscovery Procedures
        Legal hold notification process.
        Data preservation requirements.
        Hold tracking and monitoring.
        Release procedures defined.
        eDiscovery response protocols.
        """

        documents[
            "records_retention_schedule.txt"
        ] = """
        Corporate Records Retention Schedule
        Record categories and retention periods.
        Regulatory retention requirements.
        Destruction authorization process.
        Retention schedule exceptions.
        Annual schedule review process.
        """

        documents[
            "audit_committee_charter.txt"
        ] = """
        Audit Committee Charter and Responsibilities
        Committee composition requirements.
        Meeting frequency and quorum.
        Oversight responsibilities defined.
        External auditor relationship.
        Financial reporting oversight.
        """

        # Add remaining cluster documents (Risk, Business Continuity, etc.)
        # These would follow similar patterns...

        return documents

    def test_bt002_cluster_coherence_validation(
        self, labeled_document_clusters, semantic_corpus_documents
    ):
        """Test BT-002: Document clustering achieves coherent topic groups.

        Given: Documents with known topic labels
        When: Clustering via LSA + K-means
        Then: Silhouette score â‰¥ 0.65

        Behavioral Outcome: Related audit documents (same risk domain,
        control family) cluster together naturally.
        """
        # Arrange
        documents = list(semantic_corpus_documents.values())
        document_ids = list(semantic_corpus_documents.keys())

        # Expected number of clusters
        n_clusters = len(labeled_document_clusters)

        # Initialize processors
        lsa_processor = LSAProcessor(n_components=100)
        clusterer = DocumentClusterer(n_clusters=n_clusters)

        # Act
        lsa_vectors = lsa_processor.fit_transform(documents)
        predicted_clusters = clusterer.fit_predict(lsa_vectors)

        # Calculate silhouette score
        coherence_score = silhouette_score(lsa_vectors, predicted_clusters)

        # Validate domain clustering accuracy
        domain_accuracy = self._validate_domain_clustering(
            document_ids, predicted_clusters, labeled_document_clusters
        )

        # Check for singleton clusters
        cluster_sizes = np.bincount(predicted_clusters)
        has_singletons = np.any(cluster_sizes == 1)

        # Calculate inter-cluster distance
        inter_cluster_dist = self._calculate_inter_cluster_distance(lsa_vectors, predicted_clusters)

        # Log cluster metrics
        self._log_cluster_metrics(
            {
                "silhouette_score": coherence_score,
                "n_clusters": n_clusters,
                "cluster_sizes": cluster_sizes.tolist(),
                "min_cluster_size": int(np.min(cluster_sizes)),
                "max_cluster_size": int(np.max(cluster_sizes)),
                "has_singleton_clusters": has_singletons,
                "domain_accuracy": domain_accuracy,
                "inter_cluster_distance": inter_cluster_dist,
                "explained_variance": lsa_processor.get_explained_variance(),
            }
        )

        # Assert behavioral outcomes
        assert (
            coherence_score >= 0.65
        ), f"Cluster coherence {coherence_score:.2f} below threshold 0.65"
        assert not has_singletons, "Singleton clusters detected"
        assert (
            domain_accuracy >= 0.80
        ), f"Domain clustering accuracy {domain_accuracy:.2f} below threshold 0.80"

    def _validate_domain_clustering(
        self,
        document_ids: List[str],
        predicted_clusters: np.ndarray,
        labeled_clusters: Dict[str, Dict],
    ) -> float:
        """Validate that documents from same domain cluster together.

        Args:
            document_ids: List of document IDs.
            predicted_clusters: Predicted cluster labels.
            labeled_clusters: Ground truth cluster labels.

        Returns:
            Accuracy of domain clustering.
        """
        # Create ground truth mapping
        doc_to_true_cluster = {}
        for cluster_name, cluster_info in labeled_clusters.items():
            for doc in cluster_info["documents"]:
                if doc in document_ids:
                    doc_to_true_cluster[doc] = cluster_name

        # Calculate accuracy for documents that have labels
        correct = 0
        total = 0

        for i, doc_id in enumerate(document_ids):
            if doc_id in doc_to_true_cluster:
                true_cluster = doc_to_true_cluster[doc_id]
                pred_cluster = predicted_clusters[i]

                # Find majority true cluster for this predicted cluster
                cluster_docs = [
                    document_ids[j]
                    for j in range(len(document_ids))
                    if predicted_clusters[j] == pred_cluster
                ]

                true_labels = [
                    doc_to_true_cluster.get(doc)
                    for doc in cluster_docs
                    if doc in doc_to_true_cluster
                ]

                if true_labels:
                    majority_label = max(set(true_labels), key=true_labels.count)
                    if true_cluster == majority_label:
                        correct += 1
                total += 1

        return correct / total if total > 0 else 0.0

    def _calculate_inter_cluster_distance(
        self, vectors: np.ndarray, cluster_labels: np.ndarray
    ) -> float:
        """Calculate average distance between cluster centers.

        Args:
            vectors: Document vectors.
            cluster_labels: Cluster assignments.

        Returns:
            Average inter-cluster distance.
        """
        n_clusters = len(np.unique(cluster_labels))
        cluster_centers = []

        for i in range(n_clusters):
            cluster_vectors = vectors[cluster_labels == i]
            if len(cluster_vectors) > 0:
                center = np.mean(cluster_vectors, axis=0)
                cluster_centers.append(center)

        # Calculate pairwise distances between centers
        distances = []
        for i in range(len(cluster_centers)):
            for j in range(i + 1, len(cluster_centers)):
                dist = np.linalg.norm(cluster_centers[i] - cluster_centers[j])
                distances.append(dist)

        return np.mean(distances) if distances else 0.0

    def _log_cluster_metrics(self, metrics: Dict):
        """Log clustering metrics for diagnostics.

        Args:
            metrics: Dictionary of metrics to log.
        """
        print("\n" + "=" * 60)
        print("BT-002: Cluster Coherence Behavioral Metrics")
        print("=" * 60)
        for key, value in metrics.items():
            if isinstance(value, float):
                print(f"{key:25s}: {value:.3f}")
            elif isinstance(value, list):
                print(f"{key:25s}: {value}")
            else:
                print(f"{key:25s}: {value}")
        print("=" * 60)
