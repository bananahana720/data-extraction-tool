---
source: test_case_05_technical_dense.txt
format: text
---

TECHNICAL RESEARCH PAPER - PREPRINT
====================================
Title: "Adversarial Robustness in Transformer-Based Neural Architecture 
       Search via Differentiable Architecture Pruning and Lipschitz 
       Regularization"

Authors: Chen, L.Â¹*, Rodriguez-Martinez, A.Â²*, Kim, J.Â³, Patel, S.Â¹
         Â¹MIT CSAIL, Â²Stanford AI Lab, Â³Seoul National University
         *Equal contribution
ArXiv: 2410.xxxxx [cs.LG] | Submitted: 2024-10-28

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ABSTRACT

We present DART-NAS (Differentiable Adversarial Robustness via 
Transformer Neural Architecture Search), a novel framework for discovering 
neural architectures that exhibit superior robustness against adversarial 
perturbations while maintaining competitive clean accuracy. Our approach 
combines gradient-based architecture search with Lipschitz-constrained 
weight regularization (Î»_lip = 0.01) and achieves state-of-the-art 
performance on ImageNet (Îµ = 8/255 PGD-10): 67.3% robust accuracy vs. 
62.1% (WideResNet-28-10) and 64.8% (ViT-B/16 + AT). We demonstrate that 
architectural choicesâ€”particularly attention head dimensionality 
(d_k âˆˆ [32, 128]) and FFN expansion ratios (r_ffn âˆˆ [2, 8])â€”significantly 
impact adversarial robustness (ÏƒÂ² = 14.7% variance explained, p < 0.001).

Keywords: neural architecture search, adversarial robustness, transformers,
          Lipschitz continuity, automated machine learning

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# 1. INTRODUCTION

The vulnerability of deep neural networks (DNNs) to adversarial examples 
[Szegedy et al., 2014] poses critical challenges for safety-critical 
applications. While adversarial training (AT) [Madry et al., 2018] remains 
the de facto defense, it often requires manually designed architectures 
and suffers from the robustness-accuracy trade-off [Zhang et al., 2019].

Recent work in Neural Architecture Search (NAS) [Zoph & Le, 2017; Liu et 
al., 2019] has automated architecture design for clean accuracy, but 
adversarial robustness has received limited attention. We address this gap 
by formulating robust architecture search as a bi-level optimization:

min_{Î±} max_{||Î´||_p â‰¤ Îµ} L(f(x + Î´; w*(Î±), Î±), y)     (1)
    s.t. w*(Î±) = argmin_w L(f(x; w, Î±), y)                  (2)

where Î± represents architectural parameters (e.g., layer connectivity, 
operator choices), w denotes network weights, f(Â·) is the model, L(Â·) is 
the loss function, and Î´ represents adversarial perturbations bounded by 
Îµ in the L_p norm.

# Our key contributions:

[1] A differentiable architecture search framework optimizing for both 
    clean and robust accuracy via smooth relaxation of discrete choices:
    
    Ïƒ(Î±_i,j) = exp(Î±_i,j) / Î£_k exp(Î±_i,k)                (3)

[2] Lipschitz-regularized weight training with spectral normalization:
    
    ||âˆ‚f/âˆ‚x|| â‰¤ Î _{l=1}^L ||W_l||_2 â‰¤ K_lip                (4)
    
    where ||W_l||_2 is the largest singular value of layer l.

[3] Theoretical analysis proving that architectures with controlled 
    Lipschitz constants exhibit bounded adversarial perturbation 
    propagation (Theorem 3.1).

[4] Empirical validation across CIFAR-10/100, ImageNet, showing 
    +5.2% robust accuracy improvement over manual designs with 
    3.2Ã— faster search (GPU-hours: 847 vs. 2,712).

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# 2. METHODOLOGY

# 2.1 Search Space Definition

# We define a hierarchical search space S = {S_macro, S_micro} where:

S_macro = {N_layers âˆˆ [12, 48], d_model âˆˆ [256, 1024], N_heads âˆˆ [4, 16]}
S_micro = {O_attn, O_ffn, O_norm, O_act, O_skip}

Each micro operation O âˆˆ S_micro has associated latency Ï„(O) and memory 
Î¼(O). We constrain search via multi-objective optimization:

# min_{Î± âˆˆ S} {-R(Î±), -A(Î±), Ï„(Î±), Î¼(Î±)}                 (5)

where R(Î±) = robust accuracy, A(Î±) = clean accuracy, Ï„(Î±) = inference 
latency, Î¼(Î±) = memory footprint.

Pareto-optimal solutions found via NSGA-III [Deb & Jain, 2014] with 
reference directions D = 100, population size P = 50.

# 2.2 Differentiable Architecture Representation

Following DARTS [Liu et al., 2019], we relax categorical choices via 
continuous architectural parameters:

x^{(l+1)} = Î£_{i=1}^{|O|} (exp(Î±_i^{(l)}) / Î£_j exp(Î±_j^{(l)})) Â· O_i(x^{(l)})    (6)

# To prevent gradient collapse, we apply temperature annealing:

# T(epoch) = T_0 Â· (T_min/T_0)^{epoch/E_max}             (7)

with T_0 = 1.0, T_min = 0.01, E_max = 50.

# 2.3 Adversarial Training Integration

During architecture search, we employ Fast Adversarial Training (FAT) 
[Wong et al., 2020] with random initialization:

Î´ ~ Uniform(-Îµ, Îµ)                                      (8)
    Î´ = Î´ + Î± Â· sign(âˆ‡_Î´ L(f(x + Î´), y))                   (9)
    Î´ = Î _{||Â·||_âˆ â‰¤ Îµ}(Î´)                                  (10)

where Î± = 2Îµ/K for K = 7 steps, Îµ = 8/255 for CIFAR-10.

# We augment the loss with Lipschitz regularization:

# L_total = L_ce + Î»_lip Â· (||âˆ‡_x f||_2 - K_target)Â²     (11)

where K_target = 10.0 empirically determined via grid search.

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# 3. THEORETICAL ANALYSIS

Theorem 3.1 (Adversarial Perturbation Bound): Let f: â„^n â†’ â„^m be a 
neural network with Lipschitz constant K_lip. For any adversarial 
perturbation Î´ with ||Î´||_p â‰¤ Îµ, the output perturbation satisfies:

# ||f(x + Î´) - f(x)||_q â‰¤ K_lip Â· Îµ Â· n^{1/p - 1/q}      (12)

where 1/p + 1/q = 1 (HÃ¶lder conjugates).

Proof: By Lipschitz continuity,
    ||f(x + Î´) - f(x)||_q â‰¤ K_lip Â· ||Î´||_p
                           â‰¤ K_lip Â· Îµ

For p = âˆ, q = 1: ||Î´||_âˆ â‰¤ Îµ implies ||Î´||_1 â‰¤ nÂ·Îµ
Therefore: ||f(x + Î´) - f(x)||_1 â‰¤ K_lip Â· n Â· Îµ            â–¡

Corollary 3.1.1: Architectures with lower K_lip exhibit bounded 
adversarial vulnerability with probability â‰¥ 1 - exp(-Î»K_lipÂ²).

Lemma 3.2 (Gradient Flow Stability): Under Lipschitz constraints, 
gradient magnitudes during architecture search satisfy:

# ğ”¼[||âˆ‡_Î± L||_2] â‰¤ C Â· âˆš(d_Î±) Â· K_lip                    (13)

where d_Î± is the dimensionality of architecture parameters and C is a 
problem-dependent constant.

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# 4. EXPERIMENTAL SETUP

# 4.1 Datasets & Evaluation Metrics

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Dataset      â”‚ Train Size  â”‚ Test Size    â”‚ Resolution  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CIFAR-10     â”‚ 50,000      â”‚ 10,000       â”‚ 32Ã—32Ã—3     â”‚
â”‚ CIFAR-100    â”‚ 50,000      â”‚ 10,000       â”‚ 32Ã—32Ã—3     â”‚
â”‚ ImageNet     â”‚ 1,281,167   â”‚ 50,000       â”‚ 224Ã—224Ã—3   â”‚
â”‚ SVHN         â”‚ 73,257      â”‚ 26,032       â”‚ 32Ã—32Ã—3     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Adversarial Attacks:
â€¢ PGD (Projected Gradient Descent): Îµ âˆˆ {4/255, 8/255, 16/255}, 
  step size Î± = 2Îµ/K, iterations K âˆˆ {10, 20, 50}
â€¢ AutoAttack [Croce & Hein, 2020]: ensemble of APGD-CE, APGD-DLR, 
  FAB-T, Square Attack
â€¢ C&W [Carlini & Wagner, 2017]: Îº = 0, learning rate = 0.01, 
  binary search steps = 9

Metrics:
- Clean Accuracy: A_clean = (1/N) Î£_i ğŸ™[argmax f(x_i) = y_i]
- Robust Accuracy: A_robust = (1/N) Î£_i min_{||Î´||_âˆâ‰¤Îµ} ğŸ™[argmax f(x_i+Î´) = y_i]
- Average Perturbation Distance (APD): ğ”¼_x[min_Î´ ||Î´||_2 s.t. argmax f(x+Î´) â‰  y]

# 4.2 Implementation Details

Hardware: 8Ã— NVIDIA A100 (80GB) GPUs
Framework: PyTorch 2.1.0 + CUDA 12.1 + cuDNN 8.9.0
Search Time: 847 GPU-hours (CIFAR-10), 2,134 GPU-hours (ImageNet)

Hyperparameters:
```python
config = {
    "search": {
        "optimizer": "Adam",
        "lr": 0.001,
        "weight_decay": 3e-4,
        "momentum": 0.9,  # for SGD in weight training
        "epochs": 50,
        "batch_size": 64,
        "grad_clip_norm": 5.0
    },
    "train": {
        "optimizer": "SGD",
        "lr": 0.025,
        "lr_scheduler": "cosine",
        "T_max": 600,
        "eta_min": 0.0,
        "momentum": 0.9,
        "weight_decay": 3e-4,
        "epochs": 600,
        "batch_size": 128
    },
    "adversarial": {
        "epsilon": 8/255,
        "alpha": 2/255,
        "num_steps": 10,
        "random_start": True,
        "loss_fn": "ce"  # cross-entropy
    },
    "lipschitz": {
        "lambda": 0.01,
        "target_constant": 10.0,
        "spectral_norm_iter": 1
    }
}
```

Data Augmentation:
- Random crop (32Ã—32 with padding=4)
- Random horizontal flip (p=0.5)
- Cutout [DeVries & Taylor, 2017]: n_holes=1, length=16
- AutoAugment [Cubuk et al., 2019]: policy "cifar10"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# 5. RESULTS

# 5.1 Quantitative Performance

Table 1: Comparison with State-of-the-Art (CIFAR-10)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model                   â”‚ Clean Acc  â”‚ Robust Acc  â”‚ Params   â”‚
â”‚                         â”‚ (%)        â”‚ (Îµ=8/255)   â”‚ (M)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ResNet-18 (Standard)    â”‚ 94.7       â”‚ 0.0         â”‚ 11.2     â”‚
â”‚ WideResNet-28-10 [AT]   â”‚ 87.3       â”‚ 56.4        â”‚ 36.5     â”‚
â”‚ WideResNet-34-10 [TRADES]â”‚ 85.4      â”‚ 57.3        â”‚ 46.2     â”‚
â”‚ ViT-S/16 [AT]           â”‚ 86.8       â”‚ 54.9        â”‚ 22.1     â”‚
â”‚ RobustBench Best [2024] â”‚ 88.7       â”‚ 62.1        â”‚ 71.3     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ DART-NAS (ours)         â”‚ 88.9       â”‚ 67.3        â”‚ 38.7     â”‚
â”‚ DART-NAS-L (ours)       â”‚ 90.1       â”‚ 69.8        â”‚ 58.4     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Statistical Significance: Paired t-test vs. RobustBench Best
p-value = 0.0023 (Î± = 0.05), Cohen's d = 1.47 (large effect)

Table 2: Ablation Study (CIFAR-10, Îµ=8/255)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Configuration                â”‚ Clean Acc  â”‚ Robust Acc  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ DART-NAS (full)              â”‚ 88.9       â”‚ 67.3        â”‚
â”‚ - Lipschitz regularization   â”‚ 89.2       â”‚ 63.1 (-4.2) â”‚
â”‚ - Architecture search        â”‚ 87.6       â”‚ 62.8 (-4.5) â”‚
â”‚ - Temperature annealing      â”‚ 88.4       â”‚ 65.7 (-1.6) â”‚
â”‚ Only clean acc objective     â”‚ 91.3       â”‚ 58.4 (-8.9) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# 5.2 Discovered Architecture

Optimal macro-architecture (Î±*):
- N_layers = 24
- d_model = 768
- N_heads = 12
- d_k = 64 (head dimension)
- r_ffn = 4 (FFN expansion ratio)

Micro-operations selected (frequency):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Operation               â”‚ Selection â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Multi-Head Attention    â”‚ 87%       â”‚
â”‚ Separable Conv 3Ã—3      â”‚ 23%       â”‚
â”‚ Identity (skip)         â”‚ 34%       â”‚
â”‚ Layer Normalization     â”‚ 100%      â”‚
â”‚ GELU Activation         â”‚ 76%       â”‚
â”‚ SwiGLU FFN              â”‚ 24%       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Key insights:
â€¢ Attention heads with d_k = 64 optimal (vs. 32, 128)
â€¢ Skip connections every 2-3 layers improve robustness +3.2%
â€¢ Layer normalization outperforms batch norm +2.7% robust accuracy

# 5.3 Lipschitz Constant Analysis

# Measured Lipschitz constants (via power iteration, n_iter=100):

Model                    K_lip (measured)    K_lip (theoretical bound)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ResNet-18 (standard)     8472.3 Â± 847.2     âˆ (unbounded)
WideResNet-28-10 [AT]    124.7 Â± 12.4       ~150 (estimated)
DART-NAS (ours)          9.8 Â± 0.9          â‰¤ 10 (constrained)

Correlation: Spearman's Ï = -0.847 between K_lip and robust accuracy
(p < 0.001), confirming Theorem 3.1.

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# 6. COMPUTATIONAL COMPLEXITY

# Time Complexity Analysis:

# Forward Pass: O(N_layers Â· N_heads Â· d_model Â· LÂ²)
where L = sequence length

Backward Pass (architecture gradient):
    âˆ‚L/âˆ‚Î± = Î£_i (âˆ‚L/âˆ‚O_i) Â· (âˆ‚O_i/âˆ‚Î±)
    Complexity: O(|O| Â· N_layers Â· d_model Â· LÂ²)

Search Algorithm Complexity:
    Total: O(E_search Â· B Â· (T_forward + T_backward + T_adversarial))
    â‰ˆ 50 Â· 64 Â· (0.12s + 0.34s + 0.89s) = 4,320 seconds â‰ˆ 1.2 hours
    
    On 8Ã— A100 GPUs: 1.2 hours / 8 = 9 minutes per iteration
    Total search: 50 epochs Ã— 9 min = 450 min â‰ˆ 7.5 hours

Memory Footprint:
    Architecture params: |Î±| = N_layers Ã— |O| Ã— d_modelÂ²
                        = 24 Ã— 8 Ã— 768Â² â‰ˆ 113M parameters
    
    Peak GPU memory: 
        - Forward activations: ~8.7 GB
        - Backward gradients: ~12.3 GB
        - Optimizer states: ~6.2 GB
        - Total: ~27.2 GB per GPU

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# 7. LIMITATIONS & FUTURE WORK

Current Limitations:
[1] Search cost scales quadratically with d_model (O(dÂ²))
[2] Limited to L_âˆ threat model; L_2, L_1 require separate tuning
[3] Transferability to larger datasets (ImageNet-21k) untested
[4] Certified robustness bounds not provided (future: interval analysis)

Future Directions:
â€¢ Multi-threat model NAS (L_âˆ + L_2 + semantic perturbations)
â€¢ Integration with neural ODE frameworks for continuous architectures
â€¢ Theoretical analysis of robust generalization bounds
â€¢ Extension to vision-language models (CLIP, ALIGN)
â€¢ Quantum-inspired architecture search (variational quantum circuits)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# 8. CONCLUSION

We introduced DART-NAS, achieving state-of-the-art adversarial robustness 
(+5.2% over prior work) via principled architecture search with Lipschitz 
regularization. Our theoretical analysis (Theorem 3.1) and empirical 
validation (p < 0.001) confirm that architectural choices significantly 
impact robustness. The discovered architecture demonstrates that 
attention mechanisms with controlled Lipschitz constants provide superior 
robustness-accuracy trade-offs.

Code: https://github.com/dart-nas/dart-nas-official
Checkpoints: https://huggingface.co/dart-nas/cifar10-robust
Contact: {lchen, armartinez, jkim, spatel}@dartnas-authors.org

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# REFERENCES [47 total, showing key citations]

[1] Szegedy et al. (2014). Intriguing properties of neural networks. 
    ICLR 2014. arXiv:1312.6199

[2] Madry et al. (2018). Towards deep learning models resistant to 
    adversarial attacks. ICLR 2018. arXiv:1706.06083

[3] Liu et al. (2019). DARTS: Differentiable Architecture Search. 
    ICLR 2019. arXiv:1806.09055

[4] Croce & Hein (2020). Reliable evaluation of adversarial robustness 
    with an ensemble of diverse parameter-free attacks. ICML 2020.

# ... [43 additional references omitted for brevity]

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

APPENDIX A: Additional Experimental Results
APPENDIX B: Architecture Encoding Details  
APPENDIX C: Hyperparameter Sensitivity Analysis
APPENDIX D: Extended Proofs (Theorems 3.1-3.4)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Document Hash (SHA-256): 
a7f3d8c9e2b1f4a6c8d3e5f7a9b2c4d6e8f3a5b7c9d1e4f6a8c2d5e7f9a3b6c8d5

LaTeX Source: 18,473 lines | Compiled PDF: 24 pages | Word Count: 8,947
Processing Requirements: Unicode math symbols (âˆˆâˆ‚âˆ‡âˆ«Î£âˆ), subscripts/
superscripts, matrices, code blocks, citation links, cross-references