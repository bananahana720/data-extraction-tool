"""OCR confidence scoring and quality validation for extracted documents.

This module implements OCR confidence calculation, image preprocessing, and quarantine
mechanisms to ensure low-quality extractions are flagged before reaching AI systems.

Classes:
    QualityValidator: Pipeline stage for OCR confidence scoring and validation
"""

import json
from datetime import datetime
from pathlib import Path
from typing import TYPE_CHECKING, Any, Dict, List, Optional

import structlog

try:
    import pytesseract  # type: ignore[import-not-found]
    from PIL import Image, ImageEnhance, ImageFilter

    TESSERACT_AVAILABLE = True
except ImportError:
    TESSERACT_AVAILABLE = False

# Import types for type hinting only (not runtime)
if TYPE_CHECKING:
    pass

from ..core.exceptions import ProcessingError
from ..core.models import Document, ProcessingContext, QualityFlag, ValidationReport
from ..core.pipeline import PipelineStage


class QualityValidator(PipelineStage[Document, Document]):
    """OCR quality validator with confidence scoring and completeness validation.

    Implements PipelineStage protocol to calculate OCR confidence scores, apply
    image preprocessing, detect extraction gaps, and quarantine low-quality extractions.

    Attributes:
        logger: Structured logger for audit trail
        ocr_confidence_threshold: Minimum confidence threshold (default 0.95)
        ocr_preprocessing_enabled: Enable OCR preprocessing (default True)
        quarantine_low_confidence: Enable quarantine for low confidence (default True)
        completeness_threshold: Minimum completeness ratio threshold (default 0.90, Story 2.5)
    """

    def __init__(
        self,
        ocr_confidence_threshold: float = 0.95,
        ocr_preprocessing_enabled: bool = True,
        quarantine_low_confidence: bool = True,
        completeness_threshold: float = 0.90,
        logger: Optional[Any] = None,
    ) -> None:
        """Initialize quality validator.

        Args:
            ocr_confidence_threshold: Minimum confidence threshold (0.0-1.0)
            ocr_preprocessing_enabled: Enable image preprocessing for OCR
            quarantine_low_confidence: Enable quarantine mechanism
            completeness_threshold: Minimum completeness ratio threshold (0.0-1.0, Story 2.5)
            logger: Structured logger instance
        """
        self.logger = logger or structlog.get_logger(__name__)
        self.ocr_confidence_threshold = ocr_confidence_threshold
        self.ocr_preprocessing_enabled = ocr_preprocessing_enabled
        self.quarantine_low_confidence = quarantine_low_confidence
        self.completeness_threshold = completeness_threshold

        # Check if Tesseract is available
        if not TESSERACT_AVAILABLE:
            self.logger.warning(
                "tesseract_not_available",
                message="pytesseract or Pillow not installed - OCR validation will be skipped",
            )

    def validate_ocr_confidence(
        self,
        image_path: Path,
        preprocess: bool = True,
    ) -> tuple[float, Dict[str, Any]]:
        """Calculate OCR confidence score for an image.

        Uses pytesseract.image_to_data() to extract word-level confidence scores
        and calculates page-level average confidence.

        Args:
            image_path: Path to image file
            preprocess: Whether to apply preprocessing before OCR

        Returns:
            Tuple of (confidence_score, ocr_data_dict)
            - confidence_score: Average confidence (0.0-1.0)
            - ocr_data_dict: Full OCR data from pytesseract

        Raises:
            ProcessingError: If pytesseract fails or image cannot be loaded
        """
        if not TESSERACT_AVAILABLE:
            raise ProcessingError(
                "pytesseract or Pillow not installed - cannot calculate OCR confidence"
            )

        try:
            # Load image
            image = Image.open(image_path)

            # Apply preprocessing if enabled
            if preprocess and self.ocr_preprocessing_enabled:
                confidence_before = self._calculate_raw_confidence(image)
                image = self.preprocess_image_for_ocr(image)
                confidence_after = self._calculate_raw_confidence(image)

                self.logger.info(
                    "ocr_preprocessing_applied",
                    image_path=str(image_path),
                    confidence_before=confidence_before,
                    confidence_after=confidence_after,
                    improvement=confidence_after - confidence_before,
                )
            else:
                confidence_after = None

            # Get OCR data with confidence scores
            ocr_data = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)

            # Extract valid confidence scores (filter out -1 which indicates no OCR)
            confidences = [int(conf) for conf in ocr_data["conf"] if str(conf) != "-1"]

            if not confidences:
                # No text detected - return 0.0 confidence
                return 0.0, ocr_data

            # Calculate average confidence and normalize to 0.0-1.0 scale
            average_confidence = sum(confidences) / len(confidences) / 100.0

            return average_confidence, ocr_data

        except Exception as e:
            raise ProcessingError(f"Failed to calculate OCR confidence for {image_path}: {str(e)}")

    def _calculate_raw_confidence(self, image: Any) -> float:
        """Calculate raw OCR confidence for an image.

        Helper method for preprocessing confidence comparison.

        Args:
            image: PIL Image object

        Returns:
            Average confidence score (0.0-1.0)
        """
        try:
            ocr_data = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)
            confidences = [int(conf) for conf in ocr_data["conf"] if str(conf) != "-1"]

            if not confidences:
                return 0.0

            return sum(confidences) / len(confidences) / 100.0
        except Exception:
            return 0.0

    def preprocess_image_for_ocr(self, image: Any) -> Any:
        """Preprocess image for improved OCR accuracy.

        Applies deskew, denoise, and contrast enhancement to improve OCR quality.

        Args:
            image: PIL Image object to preprocess

        Returns:
            Preprocessed PIL Image object
        """
        import numpy as np

        # Convert to grayscale for better OCR
        if image.mode != "L":
            image = image.convert("L")

        # Apply deskew (rotation correction) using determine_skew from deskew library
        try:
            from deskew import determine_skew  # type: ignore[import-not-found]
            from skimage.transform import rotate  # type: ignore[import-not-found]

            # Convert PIL Image to numpy array for deskew processing
            image_array = np.array(image)

            # Determine skew angle using the deskew library
            angle = determine_skew(image_array)

            # Rotate image to correct skew if angle is detected and significant
            if angle is not None and abs(angle) > 0.1:  # Only deskew if angle > 0.1 degrees
                # Rotate using scikit-image (handles the rotation properly)
                rotated_array = rotate(image_array, angle, resize=False, preserve_range=True)
                # Convert back to uint8 and PIL Image
                image = Image.fromarray(rotated_array.astype(np.uint8))

                self.logger.debug(
                    "image_deskewed",
                    skew_angle=round(angle, 2),
                    correction_applied=True,
                )
        except Exception as e:
            # If deskew fails, log warning and continue with original image
            self.logger.warning(
                "deskew_failed",
                error=str(e),
                fallback="continuing_without_deskew",
            )

        # Apply denoise using median filter
        image = image.filter(ImageFilter.MedianFilter(size=3))

        # Apply contrast enhancement
        enhancer = ImageEnhance.Contrast(image)
        image = enhancer.enhance(1.5)

        return image

    def calculate_document_average_confidence(
        self, confidence_scores: Dict[int, float]
    ) -> Optional[float]:
        """Calculate document-level average confidence from per-page scores.

        Args:
            confidence_scores: Dictionary of page_num -> confidence score

        Returns:
            Average confidence across all pages, or None if no scores
        """
        if not confidence_scores:
            return None

        return sum(confidence_scores.values()) / len(confidence_scores)

    def check_confidence_threshold(
        self, confidence_scores: Dict[int, float]
    ) -> tuple[bool, List[int]]:
        """Check if any pages are below confidence threshold.

        Args:
            confidence_scores: Dictionary of page_num -> confidence score

        Returns:
            Tuple of (quarantine_recommended, pages_below_threshold)
            - quarantine_recommended: True if any page below threshold
            - pages_below_threshold: List of page numbers below threshold
        """
        pages_below_threshold = [
            page_num
            for page_num, confidence in confidence_scores.items()
            if confidence < self.ocr_confidence_threshold
        ]

        return len(pages_below_threshold) > 0, pages_below_threshold

    def create_validation_report(
        self,
        confidence_scores: Dict[int, float],
        pages_below_threshold: List[int],
        scanned_pdf_detected: Optional[bool] = None,
    ) -> ValidationReport:
        """Create validation report for OCR quality assessment.

        Args:
            confidence_scores: Per-page OCR confidence scores
            pages_below_threshold: List of page numbers below threshold
            scanned_pdf_detected: Whether document was detected as scanned PDF

        Returns:
            ValidationReport with quarantine recommendation and quality flags
        """
        quarantine_recommended = len(pages_below_threshold) > 0 and self.quarantine_low_confidence
        quality_flags = []
        extraction_gaps = []

        if pages_below_threshold:
            quality_flags.append(QualityFlag.LOW_OCR_CONFIDENCE)
            for page_num in pages_below_threshold:
                confidence = confidence_scores.get(page_num, 0.0)
                extraction_gaps.append(
                    f"Page {page_num}: OCR confidence {confidence:.2%} below threshold {self.ocr_confidence_threshold:.2%}"
                )

        document_avg_confidence = self.calculate_document_average_confidence(confidence_scores)

        return ValidationReport(
            quarantine_recommended=quarantine_recommended,
            confidence_scores=confidence_scores,
            quality_flags=quality_flags,
            extraction_gaps=extraction_gaps,
            document_average_confidence=document_avg_confidence,
            scanned_pdf_detected=scanned_pdf_detected,
        )

    def detect_scanned_pdf(self, document: Document) -> bool:
        """Detect if document is a scanned PDF vs. native PDF.

        Uses heuristics to determine if a PDF was scanned (images + OCR) or
        contains native digital text. Analyzes document structure and metadata
        for indicators of scanning.

        Heuristic rules:
        - If document_type is 'image' → scanned
        - If >50% of structure indicates image-based content → scanned
        - If OCR confidence scores are present in metadata → scanned
        - If document has rich font/structure metadata → native

        Args:
            document: Document to analyze

        Returns:
            True if scanned PDF detected, False if native or indeterminate
        """
        # Check document type - if explicitly marked as image, it's scanned
        if document.metadata.document_type == "image":
            self.logger.info(
                "scanned_pdf_detected",
                document_id=document.id,
                reason="document_type_is_image",
            )
            return True

        # Check if OCR confidence scores exist in metadata
        if document.metadata.ocr_confidence:
            self.logger.info(
                "scanned_pdf_detected",
                document_id=document.id,
                reason="ocr_confidence_scores_present",
                page_count=len(document.metadata.ocr_confidence),
            )
            return True

        # Analyze document structure for image vs. text content ratio
        structure = document.structure
        if not structure:
            # No structure metadata - assume native PDF
            return False

        # Count pages/blocks with image content vs. text content
        image_content_count = 0
        text_content_count = 0

        # Check for page-level indicators
        pages = structure.get("pages", [])
        for page in pages:
            if isinstance(page, dict):
                # Check if page has image blocks or OCR indicators
                has_images = page.get("has_images", False) or page.get("ocr_applied", False)
                has_text = page.get("has_text", False) or page.get("text_blocks", 0) > 0

                if has_images:
                    image_content_count += 1
                if has_text and not has_images:
                    text_content_count += 1

        # Check blocks-level structure (if available)
        blocks = structure.get("blocks", [])
        for block in blocks:
            if isinstance(block, dict):
                block_type = block.get("type", "").lower()
                if block_type in ["image", "ocr", "scanned"]:
                    image_content_count += 1
                elif block_type in ["text", "paragraph", "heading"]:
                    text_content_count += 1

        # Apply 50% threshold heuristic
        total_content = image_content_count + text_content_count
        if total_content > 0:
            image_ratio = image_content_count / total_content
            is_scanned = image_ratio > 0.5

            self.logger.info(
                "scanned_pdf_detection_heuristic",
                document_id=document.id,
                image_content_count=image_content_count,
                text_content_count=text_content_count,
                image_ratio=image_ratio,
                is_scanned=is_scanned,
            )

            return is_scanned

        # If no structure indicators found, check for other metadata
        # High font diversity suggests native PDF
        font_count = structure.get("font_count", 0)
        has_rich_fonts = font_count > 3

        if has_rich_fonts:
            self.logger.info(
                "native_pdf_detected",
                document_id=document.id,
                reason="rich_font_metadata",
                font_count=font_count,
            )
            return False

        # Default to False (native) if indeterminate
        self.logger.debug(
            "pdf_type_indeterminate",
            document_id=document.id,
            message="Insufficient metadata to determine scanned vs. native - assuming native",
        )
        return False

    def quarantine_document(
        self,
        document: Document,
        validation_report: ValidationReport,
        output_dir: Path,
    ) -> Path:
        """Quarantine low-confidence document with audit log.

        Creates quarantine directory structure and writes audit log with file hash,
        confidence scores, quality flags, and timestamp.

        Args:
            document: Document to quarantine
            validation_report: Validation report with quality assessment
            output_dir: Base output directory for quarantine files

        Returns:
            Path to quarantine directory where document should be moved

        Raises:
            ProcessingError: If quarantine directory creation fails
        """
        try:
            # Create quarantine directory structure: {output_dir}/quarantine/{date}/
            today = datetime.now().strftime("%Y-%m-%d")
            quarantine_dir = output_dir / "quarantine" / today
            quarantine_dir.mkdir(parents=True, exist_ok=True)

            # Calculate file hash for audit trail
            file_hash = document.metadata.file_hash

            # Create audit log entry
            audit_entry = {
                "file_path": str(document.metadata.source_file),
                "file_hash": file_hash,
                "document_id": document.id,
                "quarantine_reason": "low_ocr_confidence",
                "confidence_scores": validation_report.confidence_scores,
                "document_average_confidence": validation_report.document_average_confidence,
                "quality_flags": [flag.value for flag in validation_report.quality_flags],
                "extraction_gaps": validation_report.extraction_gaps,
                "timestamp": datetime.now().isoformat(),
                "threshold": self.ocr_confidence_threshold,
            }

            # Write to quarantine log (append mode)
            quarantine_log_path = quarantine_dir / "quarantine_log.json"
            log_entries = []

            # Read existing log if it exists
            if quarantine_log_path.exists():
                try:
                    with open(quarantine_log_path, "r", encoding="utf-8") as f:
                        log_entries = json.load(f)
                except json.JSONDecodeError:
                    # If log is corrupted, start fresh
                    self.logger.warning(
                        "quarantine_log_corrupted",
                        log_path=str(quarantine_log_path),
                        action="starting_new_log",
                    )
                    log_entries = []

            # Append new entry
            log_entries.append(audit_entry)

            # Write updated log
            with open(quarantine_log_path, "w", encoding="utf-8") as f:
                json.dump(log_entries, f, indent=2, ensure_ascii=False)

            self.logger.info(
                "document_quarantined",
                document_id=document.id,
                file_path=str(document.metadata.source_file),
                quarantine_dir=str(quarantine_dir),
                reason="low_ocr_confidence",
                average_confidence=validation_report.document_average_confidence,
                threshold=self.ocr_confidence_threshold,
            )

            return quarantine_dir

        except Exception as e:
            raise ProcessingError(f"Failed to quarantine document {document.id}: {str(e)}")

    def detect_missing_images(self, document: Document) -> List[Dict[str, Any]]:
        """Detect images without alt text in document structure (Story 2.5 - AC 2.5.1).

        Analyzes ContentBlocks in document.structure for block_type='image' with
        missing or empty alt text. Extracts page number and section context from
        ContentBlock metadata.

        Args:
            document: Document with structure containing ContentBlocks

        Returns:
            List of extraction gaps with location details:
            [{"gap_type": "missing_image", "location": {"page": N, "section": "..."},
              "description": "...", "severity": "warning"}]
        """
        gaps = []

        # Extract ContentBlocks from document structure
        content_blocks = document.structure.get("content_blocks", [])

        for block in content_blocks:
            # Check if block is an image
            block_type = block.get("block_type")
            if block_type != "image":
                continue

            # Extract image metadata
            metadata = block.get("metadata", {})
            alt_text = metadata.get("alt_text")

            # Check if alt text is missing or empty
            if not alt_text or (isinstance(alt_text, str) and not alt_text.strip()):
                # Extract location information
                position = block.get("position", {})
                page_num = position.get("page")
                section = metadata.get("section", "Unknown")

                # Create gap entry
                gap = self.log_extraction_gap(
                    gap_type="missing_image",
                    location={"page": page_num, "section": section},
                    description=f"Image on page {page_num}, section '{section}' - no alt text provided",
                    severity="warning",
                )
                gaps.append(gap)

        return gaps

    def detect_complex_objects(self, document: Document) -> List[Dict[str, Any]]:
        """Detect complex objects that can't be extracted (Story 2.5 - AC 2.5.2).

        Detects ContentBlocks with block_type in ['ole_object', 'chart', 'diagram', 'drawing'].
        Extracts object metadata: object_type, object_id, page, section.

        Args:
            document: Document with structure containing ContentBlocks

        Returns:
            List of extraction gaps with object details and suggested action
        """
        gaps = []
        complex_types = ["ole_object", "chart", "diagram", "drawing"]

        # Extract ContentBlocks from document structure
        content_blocks = document.structure.get("content_blocks", [])

        for block in content_blocks:
            block_type = block.get("block_type")

            # Check if block is a complex object
            if block_type not in complex_types:
                continue

            # Extract metadata
            metadata = block.get("metadata", {})
            position = block.get("position", {})
            page_num = position.get("page")
            section = metadata.get("section", "Unknown")
            object_id = metadata.get("object_id", block.get("block_id", "unknown"))

            # Create gap entry with suggested action
            gap = self.log_extraction_gap(
                gap_type="complex_object",
                location={"page": page_num, "section": section, "object_type": block_type},
                description=f"{block_type.replace('_', ' ').title()} object on page {page_num} - manual extraction required",
                severity="info",
                suggested_action=f"Manually extract {block_type} content from source document",
            )
            gap["object_id"] = object_id
            gaps.append(gap)

        return gaps

    def calculate_completeness_ratio(self, document: Document) -> float:
        """Calculate extraction completeness ratio (Story 2.5 - AC 2.5.3).

        Counts total elements from source document metadata (all ContentBlocks including skipped).
        Counts successfully extracted elements (ContentBlocks with non-empty content).
        Calculates ratio: extracted / total with division-by-zero handling.

        Args:
            document: Document with structure containing ContentBlocks

        Returns:
            Completeness ratio (0.0-1.0)
        """
        content_blocks = document.structure.get("content_blocks", [])

        # Count total elements
        total_elements = len(content_blocks)

        # Handle division by zero
        if total_elements == 0:
            return 1.0  # No elements = 100% complete by default

        # Count successfully extracted elements (non-empty content)
        extracted_elements = sum(1 for block in content_blocks if block.get("content", "").strip())

        # Calculate ratio
        ratio = extracted_elements / total_elements
        return round(ratio, 4)  # Round to 4 decimal places for consistency

    def log_extraction_gap(
        self,
        gap_type: str,
        location: Dict[str, Any],
        description: str,
        severity: str,
        suggested_action: Optional[str] = None,
    ) -> Dict[str, Any]:
        """Helper method for structured gap logging (Story 2.5 - AC 2.5.4, 2.5.6).

        Creates structured gap log entry with JSON output for audit trail.

        Args:
            gap_type: Type of gap (e.g., 'missing_image', 'complex_object')
            location: Location dict with page, section, etc.
            description: Human-readable description of the gap
            severity: Severity level ('info', 'warning', 'error')
            suggested_action: Optional suggested action for remediation

        Returns:
            Gap dictionary for ValidationReport.extraction_gaps list
        """
        gap = {
            "gap_type": gap_type,
            "location": location,
            "description": description,
            "severity": severity,
        }

        if suggested_action:
            gap["suggested_action"] = suggested_action

        # Log with structlog for audit trail
        self.logger.info(
            "extraction_gap_detected",
            gap_type=gap_type,
            location=location,
            description=description,
            severity=severity,
        )

        return gap

    def process(self, document: Document, context: ProcessingContext) -> Document:
        """Apply quality validation to document (OCR + completeness).

        Orchestrates full validation workflow:
        1. Detect if document is scanned PDF (if OCR available)
        2. Calculate OCR confidence scores (if scanned and OCR available)
        3. Check confidence thresholds (if OCR available)
        4. Detect completeness issues (missing images, complex objects)
        5. Calculate completeness ratio
        6. Create validation report
        7. Populate document metadata
        8. Quarantine if needed

        Args:
            document: Document to validate
            context: Processing context with config, logger, metrics

        Returns:
            Document with enriched metadata (ocr_confidence, quality_flags, completeness_ratio)

        Raises:
            ProcessingError: If validation fails critically
        """
        # OCR validation (if available)
        ocr_validation_performed = False
        confidence_scores: Dict[int, float] = {}
        pages_below_threshold: List[int] = []
        is_scanned = False

        if not TESSERACT_AVAILABLE:
            self.logger.warning(
                "ocr_validation_skipped",
                document_id=document.id,
                reason="pytesseract_not_available",
            )
            # Skip OCR but run completeness validation
            validation_report = ValidationReport(quarantine_recommended=False)
            skip_to_completeness = True
        else:
            ocr_validation_performed = True
            skip_to_completeness = False

            self.logger.info(
                "ocr_validation_started",
                document_id=document.id,
                threshold=self.ocr_confidence_threshold,
                preprocessing_enabled=self.ocr_preprocessing_enabled,
            )

            # Step 1: Detect if document is scanned PDF
            is_scanned = self.detect_scanned_pdf(document)

            # If not scanned, skip OCR validation but continue to completeness validation
            if not is_scanned:
                self.logger.info(
                    "ocr_validation_skipped",
                    document_id=document.id,
                    reason="native_pdf_detected",
                )
                # Skip OCR but continue to completeness validation
                # Create empty validation report
                validation_report = ValidationReport(quarantine_recommended=False)
                # Jump to completeness validation
                skip_to_completeness = True
            else:
                # Step 2: Calculate OCR confidence scores
                # Note: In a real implementation, we would extract images from the document
                # For now, we'll use existing ocr_confidence metadata if available
                confidence_scores = document.metadata.ocr_confidence.copy()

                # If no confidence scores in metadata, skip OCR but do completeness validation
                if not confidence_scores:
                    self.logger.info(
                        "ocr_confidence_not_available",
                        document_id=document.id,
                        message="No OCR confidence scores in metadata - OCR validation skipped",
                    )
                    # Create empty validation report and continue to completeness
                    validation_report = ValidationReport(quarantine_recommended=False)
                    skip_to_completeness = True
                else:
                    skip_to_completeness = False

        if not skip_to_completeness:
            # Step 3: Check confidence thresholds
            quarantine_recommended, pages_below_threshold = self.check_confidence_threshold(
                confidence_scores
            )

            # Step 4: Create validation report
            validation_report = self.create_validation_report(
                confidence_scores=confidence_scores,
                pages_below_threshold=pages_below_threshold,
                scanned_pdf_detected=is_scanned,
            )

        # Step 4.5: Completeness validation (Story 2.5)
        # Detect missing images
        missing_image_gaps = self.detect_missing_images(document)
        missing_images_count = len(missing_image_gaps)

        # Detect complex objects
        complex_object_gaps = self.detect_complex_objects(document)
        complex_objects_count = len(complex_object_gaps)

        # Calculate completeness ratio
        completeness_ratio = self.calculate_completeness_ratio(document)
        completeness_passed = completeness_ratio >= self.completeness_threshold

        # Update validation report with completeness data
        all_gaps = missing_image_gaps + complex_object_gaps
        validation_report = validation_report.model_copy(
            update={
                "completeness_passed": completeness_passed,
                "missing_images_count": missing_images_count,
                "complex_objects_count": complex_objects_count,
                "extraction_gaps": validation_report.extraction_gaps
                + [gap["description"] for gap in all_gaps],
            }
        )

        # Add quality flags for completeness issues
        if missing_images_count > 0:
            if QualityFlag.MISSING_IMAGES not in validation_report.quality_flags:
                validation_report.quality_flags.append(QualityFlag.MISSING_IMAGES)

        if complex_objects_count > 0:
            if QualityFlag.COMPLEX_OBJECTS not in validation_report.quality_flags:
                validation_report.quality_flags.append(QualityFlag.COMPLEX_OBJECTS)

        if not completeness_passed:
            if QualityFlag.INCOMPLETE_EXTRACTION not in validation_report.quality_flags:
                validation_report.quality_flags.append(QualityFlag.INCOMPLETE_EXTRACTION)

        # Update quarantine recommendation if completeness is critically low (<85%)
        if completeness_ratio < 0.85:
            validation_report = validation_report.model_copy(
                update={"quarantine_recommended": True}
            )

        # Log completeness validation results
        self.logger.info(
            "completeness_validation_complete",
            document_id=document.id,
            completeness_ratio=completeness_ratio,
            completeness_passed=completeness_passed,
            missing_images_count=missing_images_count,
            complex_objects_count=complex_objects_count,
            total_gaps=len(all_gaps),
        )

        # Step 5: Populate document metadata with confidence scores and quality flags
        updated_metadata = document.metadata.model_copy(deep=True)

        # Add completeness ratio to metadata (Story 2.5)
        updated_metadata.completeness_ratio = completeness_ratio

        # Add OCR confidence scores to metadata (per-page)
        updated_metadata.ocr_confidence = confidence_scores

        # Add document-level average confidence to quality_scores
        if validation_report.document_average_confidence is not None:
            updated_metadata.quality_scores["ocr_average_confidence"] = (
                validation_report.document_average_confidence
            )

        # Add quality flags to metadata
        for quality_flag in validation_report.quality_flags:
            if quality_flag.value not in updated_metadata.quality_flags:
                updated_metadata.quality_flags.append(quality_flag.value)

        # Log OCR validation results
        self.logger.info(
            "ocr_validation_complete",
            document_id=document.id,
            document_average_confidence=validation_report.document_average_confidence,
            pages_below_threshold=len(pages_below_threshold),
            quality_flags=[flag.value for flag in validation_report.quality_flags],
            quarantine_recommended=validation_report.quarantine_recommended,
        )

        # Step 6: Quarantine if recommended and enabled
        if validation_report.quarantine_recommended and self.quarantine_low_confidence:
            # Get output directory from context config (or use default)
            output_dir = context.config.get("output_dir", Path("output"))
            if isinstance(output_dir, str):
                output_dir = Path(output_dir)

            try:
                self.quarantine_document(document, validation_report, output_dir)

                # Update metrics
                context.metrics["documents_quarantined"] = (
                    context.metrics.get("documents_quarantined", 0) + 1
                )
            except ProcessingError as e:
                # Log error but continue processing (graceful degradation)
                self.logger.error(
                    "quarantine_failed",
                    document_id=document.id,
                    error=str(e),
                    fallback="continuing_without_quarantine",
                )

        # Update context metrics
        context.metrics["documents_validated"] = context.metrics.get("documents_validated", 0) + 1

        # Return document with updated metadata
        return document.model_copy(update={"metadata": updated_metadata})
