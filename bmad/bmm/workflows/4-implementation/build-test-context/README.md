# Build Test Context Workflow

**Purpose**: Assemble test context XML with relevant fixtures, helpers, and configuration for test execution.

**Type**: Document workflow (generates test-context.xml)

**Part of**: BMad UAT Workflow Framework (Story 2.5.3.1)

---

## Overview

The `build-test-context` workflow discovers and documents all test infrastructure needed to execute test cases. It scans fixture directories, analyzes conftest files, identifies code under test, and packages everything into a comprehensive XML context document.

## When to Use

- **After test case creation**: When test cases have been generated by create-test-cases
- **Before test execution**: To ensure all fixtures and helpers are available
- **For test planning**: To understand setup requirements and identify gaps
- **UAT preparation**: As the second step in the UAT workflow pipeline

## Input Requirements

**Required**:
- Test cases file (from create-test-cases workflow)
- Story markdown file

**Optional**:
- Story context XML (reuses development context if available)
- Explicit paths can be provided via variables

## Output

**File**: `docs/uat/test-context/{story_key}-test-context.xml`

**Contents**:
- Test fixtures inventory with paths and descriptions
- Helper functions from conftest.py files
- pytest configuration and markers
- Source code files under test
- Integration points and setup requirements
- Missing fixtures that need creation
- Setup recommendations and commands

## Usage

### Basic Usage

```bash
workflow build-test-context
```

The workflow will:
1. Find the most recent test cases file
2. Discover all relevant test infrastructure
3. Generate comprehensive test context XML

### Specify Test Cases File

```bash
workflow build-test-context test_cases_file=docs/uat/test-cases/2.5-3.1-test-cases.md
```

### Include Story Context

```bash
workflow build-test-context include_story_context=true
```

This reuses code artifacts from the story-context workflow to avoid duplication.

### Skip Story Context

```bash
workflow build-test-context include_story_context=false
```

This builds test context from scratch without leveraging story context.

## Workflow Pipeline Position

This is **Step 2** in the UAT workflow pipeline:

```
┌─────────────────────┐
│ create-test-cases   │
│ (Story → Test Cases)│
└──────────┬──────────┘
           ↓
┌─────────────────────┐
│ build-test-context  │ ← YOU ARE HERE
│ (Gather fixtures)   │
└──────────┬──────────┘
           ↓
┌─────────────────────┐
│ execute-tests       │
│ (Run tests)         │
└──────────┬──────────┘
           ↓
┌─────────────────────┐
│ review-uat-results  │
│ (QA approval)       │
└─────────────────────┘
```

## Discovery Process

### 1. Test Fixtures

Scans `tests/fixtures/` directory structure:

```
tests/fixtures/
├── pdfs/           # PDF test files
│   ├── small/
│   └── large/
├── xlsx/           # Excel test files
├── docx/           # Word test files
├── images/         # Image test files
├── csv/            # CSV test files
└── json/           # JSON test files
```

For each test case requiring test data:
- Matches fixture type to test requirements
- Finds appropriate size variant (small/large)
- Documents fixture path and characteristics
- Identifies missing fixtures

### 2. Test Helpers

Loads conftest files:
- `tests/conftest.py` - Global fixtures
- `tests/integration/conftest.py` - Integration fixtures

Extracts:
- Shared fixtures (temp directories, mock objects, etc.)
- Setup/teardown functions
- Factory functions
- Utility helpers

### 3. pytest Configuration

Parses `pytest.ini`:
- Test markers (unit, integration, performance, etc.)
- Timeout settings
- Coverage configuration
- Plugin settings

### 4. Code Under Test

Maps test cases to source files:
- Identifies modules being tested
- Documents function/class signatures
- Notes dependencies and imports
- References related modules

### 5. Integration Points

Identifies external dependencies:
- File system requirements
- External commands (CLI tools)
- Environment variables
- Network resources (if applicable)
- Database setup (if applicable)

## Test Context XML Structure

```xml
<test-context>
  <metadata>
    <!-- Story and test case metadata -->
  </metadata>

  <testCases>
    <!-- Summary and list of test cases -->
  </testCases>

  <fixtures>
    <!-- Available fixtures and generation scripts -->
    <!-- Missing fixtures that need creation -->
  </fixtures>

  <helpers>
    <!-- conftest fixtures and utility functions -->
  </helpers>

  <configuration>
    <!-- pytest settings and markers -->
    <!-- Environment variables -->
  </configuration>

  <codeUnderTest>
    <!-- Source files being tested -->
  </codeUnderTest>

  <integrationPoints>
    <!-- External dependencies and setup -->
  </integrationPoints>

  <storyContext>
    <!-- Development context (if included) -->
  </storyContext>

  <setupRequirements>
    <!-- Prerequisites and setup steps -->
  </setupRequirements>
</test-context>
```

## Next Steps After Generation

1. **Review test context**: Validate fixture availability and helper coverage
2. **Create missing fixtures**: Use generation scripts or manual creation
   ```bash
   python scripts/generate_large_pdf_fixture.py
   ```
3. **Verify setup**: Run validation commands
   ```bash
   pytest --collect-only -m unit
   ```
4. **Execute tests**: Run via execute-tests workflow
   ```bash
   workflow execute-tests
   ```

## Configuration

The workflow uses BMM config values from `bmad/bmm/config.yaml`:

- `dev_story_location`: Where to find story files
- `output_folder`: Where to save test context (docs/)
- `user_name`: Document author
- `communication_language`: Workflow interaction language

The workflow also uses hardcoded test infrastructure paths:
- `tests/fixtures/` - Fixture root directory
- `tests/integration/` - Integration test root
- `tests/conftest.py` - Global pytest configuration
- `pytest.ini` - pytest settings

## Examples

### Example 1: Standard Context Building

```bash
workflow build-test-context
```

Output: `docs/uat/test-context/2.5-3.1-test-context.xml`
- Discovers all fixtures in tests/fixtures/
- Loads both conftest.py files
- Includes story context if available

### Example 2: Specific Test Cases File

```bash
workflow build-test-context \
  test_cases_file=docs/uat/test-cases/2.5-2-test-cases.md
```

Output: Test context for Story 2.5.2 with fixture discovery

### Example 3: Standalone Context (No Story Context)

```bash
workflow build-test-context include_story_context=false
```

Output: Test context built from test infrastructure only

## Troubleshooting

**Issue**: "Test cases file not found"
**Solution**: Run create-test-cases workflow first or provide explicit path

**Issue**: "Story context not found"
**Solution**: Set include_story_context=false or run story-context workflow

**Issue**: "No fixtures discovered"
**Solution**: Verify tests/fixtures/ directory exists and contains test data

**Issue**: "conftest.py not found"
**Solution**: Verify test structure - workflow continues with available files

## Fixture Generation

If missing fixtures are identified, the workflow provides guidance:

### Using Generation Scripts

```bash
# Generate large PDF fixture
python scripts/generate_large_pdf_fixture.py

# Generate large Excel fixture
python scripts/generate_large_excel_fixture.py

# Generate scanned PDF fixture
python scripts/generate_scanned_pdf_fixture.py
```

### Manual Fixture Creation

1. Create fixture in appropriate subdirectory
2. Document in tests/fixtures/README.md
3. Update fixture inventory
4. Regenerate test context

## Relationship to Story Context

The build-test-context workflow is similar to story-context but focused on testing:

| Aspect | story-context | build-test-context |
|--------|---------------|-------------------|
| Purpose | Development context | Testing context |
| Focus | Implementation | Validation |
| Artifacts | Source code, architecture | Fixtures, helpers |
| Output | .context.xml (for dev) | .test-context.xml (for testing) |
| When | Before development | Before test execution |

Both workflows can run independently or leverage each other's outputs.

## Related Workflows

- **create-test-cases**: Generates test cases that this workflow uses as input
- **execute-tests**: Uses the test context XML to run tests
- **review-uat-results**: Reviews test execution results
- **story-context**: Parallel workflow for development context

## Integration with Testing Infrastructure

The workflow understands the project's test structure:

```
tests/
├── unit/              # Fast, isolated tests
├── integration/       # Multi-component tests
├── performance/       # Benchmarks and stress tests
├── fixtures/          # Shared test data ← Scanned by this workflow
├── conftest.py        # Global fixtures ← Parsed by this workflow
└── integration/
    └── conftest.py    # Integration fixtures ← Parsed by this workflow
```

## Author

Created as part of Epic 2.5 - Testing Infrastructure (Story 2.5.3.1)

## Version

1.0.0 - Initial release
